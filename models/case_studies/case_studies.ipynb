{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "siqa solo# Case Studies:\n",
    "- VGG-16 (from Keras models repository, fine tuned)\n",
    "- ResNet152\n",
    "- XCeption\n",
    "\n",
    "> https://www.topbots.com/important-cnn-architectures/"
   ],
   "id": "350b825d7a2597e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# https://keras.io/guides/transfer_learning/",
   "id": "f9f1cecb54733ab7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Xception\n",
    "Before training and fine tuning lets see the performance of the pretrained model on some samples."
   ],
   "id": "cd51aeb3cecd018"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "95abf81ca4ac0032"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper\n",
    "\n",
    "from dataset.dataset_loader import dataset_loader\n",
    "\n",
    "train, test = dataset_loader((299, 299), is_grayscale=False)\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=16, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test, batch_size=16, shuffle=True)"
   ],
   "id": "c1bbcd85a7dc293a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "label_mappings = {0: \"chihuahua\", 1: \"muffin\"}\n",
    "untouched_xception = keras.applications.Xception(weights='imagenet')"
   ],
   "id": "2e03e311896aa47a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_xception(image, xception, verbose: bool = False):\n",
    "    local_image = torch.permute(image, (1, 2, 0))\n",
    "    local_image = numpy.expand_dims(local_image, 0)\n",
    "\n",
    "    return keras.applications.xception.decode_predictions(xception.predict(local_image, verbose=verbose), top=3)[0]"
   ],
   "id": "2bb17d64ca75d580",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "# todo make method\n",
    "# We look at 8 samples directly\n",
    "VISUALIZE_SAMPLES: int = 8\n",
    "image_list: list = []\n",
    "\n",
    "evaluations: list[tuple] = []\n",
    "\n",
    "for i in torch.rand(VISUALIZE_SAMPLES):\n",
    "    image = test[int(i * len(test))][0]\n",
    "    evaluations.append((evaluate_xception(image, untouched_xception), test[int(i * len(test))][1]))\n",
    "    image_list.append(torch.permute(image, (1, 2, 0)))\n",
    "\n",
    "fig = px.imshow(np.array(image_list), binary_string=True, facet_col=0, facet_col_wrap=4)\n",
    "fig.show()\n",
    "\n",
    "for i in range(len(evaluations)):\n",
    "    print(\n",
    "        f\"For facet {i} Xception has prediceted: {[i[1] for i in evaluations[i][0]]} while the true label is {label_mappings[evaluations[i][1]]}\")"
   ],
   "id": "4786b908a5c73d33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The model does not recognize Muffins as being muffins just as bakery (Which makes sense)\n",
    "# As the label Muffin is missing in the decoding of the Xception we just map it to bakery"
   ],
   "id": "3b61df463b12a6e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Evaluation without training",
   "id": "3fe0e9ae9d0a6767"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import keras\n",
    "# todo make method for all this\n",
    "predictions: list[tuple[list, int]] = [(evaluate_xception(i[0], untouched_xception), i[1]) for i in test]"
   ],
   "id": "50e019d48ef72cd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label_mappings = {0: [\"chihuahua\", \"dog\"], 1: [\"muffin\", \"bakery\"]}\n",
    "TP = 0 # True positives\n",
    "for i in range(len(predictions)):\n",
    "    predicted_values = [j[1].lower() for j in predictions[i][0]]\n",
    "    true_label = label_mappings[predictions[i][1]]\n",
    "    \n",
    "    TP += 1 if set(predicted_values) & set(true_label) else 0\n",
    "    \n",
    "precision = TP / len(predictions)\n",
    "precision # On the top 3 considering the fact that many miss classifications happen for the fact that the labels are more accurate for the dogs (some samples in the training set are not chihuahuas) and that Muffins do not have a real label."
   ],
   "id": "93359fabc60beab8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine tuning the model",
   "id": "7762e48f7089294d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.structure.augmentation_wrapper import InvertedChannelsAugmentationWrapper\n",
    "\n",
    "\n",
    "# With augmentation just to permute here\n",
    "class XceptionAugmented(InvertedChannelsAugmentationWrapper):\n",
    "    def make_augmentation(self, input_shape: (int, int, int)) -> tuple[keras.Layer, keras.Layer]:\n",
    "        input_layer = keras.Input(shape=input_shape, name=self.__class__.__name__)\n",
    "        output_layer = keras.layers.Permute(dims=(2, 3, 1))(input_layer)  # Move channels to be last\n",
    "\n",
    "        return input_layer, output_layer\n",
    "\n",
    "    def make_layers(self, input_shape: (int, int, int)) -> tuple[keras.Layer, keras.Layer]:\n",
    "        inputs = keras.Input(input_shape)\n",
    "        x = keras.applications.xception.preprocess_input(inputs, data_format=\"channels_last\")\n",
    "        x = keras.applications.Xception(weights='imagenet', include_top=False)(x, training=False, pooling='max')\n",
    "        outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        return inputs, outputs"
   ],
   "id": "7c00a10b3e288eb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = XceptionAugmented().make_model((3, 299, 299))\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "model.summary()"
   ],
   "id": "32bc7db2127080f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "history = model.fit(local_train, epochs=20, validation_data=validation_dataloader)",
   "id": "d2ea8f80435452a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# VGG-16\n",
    "https://arxiv.org/abs/1409.1556"
   ],
   "id": "742da383b8529833"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "df6dac40d21cf5af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper\n",
    "\n",
    "from dataset.dataset_loader import dataset_loader\n",
    "\n",
    "train, test = dataset_loader((224, 224), is_grayscale=False)\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=16, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test, batch_size=16, shuffle=True)"
   ],
   "id": "174568df8984bf9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model evaulation without training",
   "id": "f6984c686d18a7fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "untouched_vgg16 = keras.applications.VGG16(weights='imagenet')",
   "id": "8849a8ce2c3639b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_vgg16(image, vgg16, verbose: bool = False):\n",
    "    local_image = torch.permute(image, (1, 2, 0))\n",
    "    local_image = numpy.expand_dims(local_image, 0)\n",
    "\n",
    "    return keras.applications.vgg16.decode_predictions(vgg16.predict(local_image, verbose=verbose), top=3)[0]"
   ],
   "id": "261473ad88fd5be1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "# todo make this a method. We repeat it 3 times like idiots\n",
    "# We look at 8 samples directly\n",
    "VISUALIZE_SAMPLES: int = 8\n",
    "image_list: list = []\n",
    "\n",
    "evaluations: list[tuple] = []\n",
    "\n",
    "for i in torch.rand(VISUALIZE_SAMPLES):\n",
    "    image = test[int(i * len(test))][0]\n",
    "    evaluations.append((evaluate_vgg16(image, untouched_vgg16), test[int(i * len(test))][1]))\n",
    "    image_list.append(torch.permute(image, (1, 2, 0)))\n",
    "\n",
    "fig = px.imshow(np.array(image_list), binary_string=True, facet_col=0, facet_col_wrap=4)\n",
    "fig.show()\n",
    "\n",
    "for i in range(len(evaluations)):\n",
    "    print(\n",
    "        f\"For facet {i} VGG16 has prediceted: {[i[1] for i in evaluations[i][0]]} while the true label is {label_mappings[evaluations[i][1]]}\")"
   ],
   "id": "4ec17999abb7e0f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import keras\n",
    "\n",
    "predictions: list[tuple[list, int]] = [(evaluate_vgg16(i[0], untouched_vgg16), i[1]) for i in test]"
   ],
   "id": "a39c84388187ef30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "label_mappings = {0: [\"chihuahua\", \"dog\"], 1: [\"muffin\", \"bakery\"]}\n",
    "TP = 0 # True positives\n",
    "for i in range(len(predictions)):\n",
    "    predicted_values = [j[1].lower() for j in predictions[i][0]]\n",
    "    true_label = label_mappings[predictions[i][1]]\n",
    "\n",
    "    TP += 1 if set(predicted_values) & set(true_label) else 0\n",
    "\n",
    "precision = TP / len(predictions)\n",
    "precision # On the top 3 considering the fact that many miss classifications happen for the fact that the labels are more accurate for the dogs (some samples in the training set are not chihuahuas) and that Muffins do not have a real label."
   ],
   "id": "394145f5f0d68c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine tuning the model",
   "id": "35ad05782b3e03a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Resnet-152",
   "id": "4d7be585d468f546"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "c27ecdfb994897aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model evaluation without training",
   "id": "417efc142e2a1dbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine tuning the model",
   "id": "13b99a747c973ff5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d8a2774ea1d6a75",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
