{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "57b6744d2ded6408"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T13:45:11.537365Z",
     "start_time": "2024-04-16T13:45:11.535695Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# Why Torch? You'll find the answer in the .md files! \n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T08:36:38.518238Z",
     "start_time": "2024-04-27T08:36:37.757537Z"
    }
   },
   "id": "8fe3b7c555579820",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "db4edd7ce90d7078"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As theoretical evidence goes it is possible to approximate any $f$ by a simple NN with only one hidden layer. \n",
    "This becomes rapidly unfeasible as the number of neurons grows exponentially with the number of features of the data.($ \\Omega(2^{d/3})$) (todo check)\n",
    "\n",
    "Adding more layers might help reduce the complexity but are also harder to train as they have the issue of the vanishing gradient. We will try to build some networks like this and see if adding layers and redistributing neurons help to achieve acceptable results. (1)\n",
    "\n",
    "Most of the best results in computer vision are obtained via CNNs therefore we will try to figure out a model that achieves better results than the handcrafted DNN. After that we try to use an autotuner to learn the most optimal configuration for the CNN. (2)\n",
    "\n",
    "Once done with these 2 approaches we analise some pre-trained that we fine tune for our problem. \n",
    "Those models will be picked from a list of important CNN that are considered some useful case studies. (3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ede008945f64b7ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "http://www.faqs.org/faqs/ai-faq/neural-nets/part1/preamble.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b88ef86668619a34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Keras Model Definition\n",
    "### Should we do subclassing of the keras.Model?\n",
    "At first it seemed like the best idea as loading the Dataset via torch posed a problem:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "874735f5dc000886"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# Torch Dataset entry shape: (None, 3, 224, 224)\n",
    "# Keras def. data shape: (None, 224, 224, 3)\n",
    "\n",
    "# By setting the channels first the data can correctly be handled via data loaders defined in Pytorch\n",
    "keras.layers.MaxPool2D(data_format=\"channels_first\")\n",
    "# Therefore we don't need to permute the input batch values in the fit step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42c1a20f5f4e9cd9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "There actually is no valid reason if not coherence with the structure of the project. From Keras documentation:\n",
    "\n",
    ">Should you use the Keras functional API to create a new model, or just subclass the Model class directly? In general, the functional API is higher-level, easier and safer, and has a number of features that subclassed models do not support.\n",
    "\n",
    "The functional API is preferred and is what we will be using now. \n",
    "This means that all subclassing I implemented, which might be overkill, have been dismantled.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beef3ca35b85ef28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimizer Choice\n",
    "Optimizer considerations are under the file \"optimizer_choice.md\", what we will do is the following:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "281404cb186a5738"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8f8dd8711a0fe39"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## We try to find  a good SGD learning rate scheduler adn use it with SGD + momentum.\n",
    "## We also try with AdaDelta without any parameter (as it goes we have seen)\n",
    "## For ADAM we try scouting the parameters."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T15:48:31.077032Z",
     "start_time": "2024-03-13T15:48:31.075391Z"
    }
   },
   "id": "ef84922c37692a3a",
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Why we won't be using ADAM",
   "id": "1a74edf0c252169d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Study\n",
    "To create a valid model we have to take different topics in consideration. Some of those are parameters of the networks while others nott so much as learning rate and batch size.\n",
    "\n",
    "We will make considerations for all we can.\n",
    "\n",
    "A good source to read:\n",
    "> https://cs231n.github.io/convolutional-networks/#conv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e74aa4c2231a19e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "809ffce1526815c1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batch Size (Hyper)\n",
    "The batch size should not be too high nor too low. As suggested we follow this rule:\n",
    "> https://arxiv.org/pdf/1606.02228.pdf#page=3&zoom=150,0,125\n",
    "\n",
    "[32, 64], [128, 256] - Good starters\n",
    "[128, 256] - GPU for more boost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96b1158ddc020b34"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b118e7c0d8bddf9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning Rate (Hyper)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f9d661c8515c469"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2468f874e33561f3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62abad4dc5aaed95"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b241a90805bb4eaf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Network Neurons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3afd3b18b13980"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2e7c2f10e4df421c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
