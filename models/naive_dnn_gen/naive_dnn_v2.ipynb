{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:18:22.900471Z",
     "start_time": "2024-04-19T22:18:22.898062Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# Why Torch? You'll find the answer in the .md files! \n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import keras\n",
    "import keras_tuner\n",
    "from k_fold_cv.k_fold_generator import KFoldController\n",
    "from utils.dataset_loader import dataset_loader\n",
    "import keras_tuner\n",
    "from k_fold_cv.k_fold_generator import KFoldController\n",
    "from utils.dataset_loader import dataset_loader\n",
    "import keras_tuner\n",
    "from torch.utils.data import DataLoader\n",
    "from models.naive_dnn_gen.naive_dnn import NaiveDNNTunableModelFamily\n",
    "from models.structure.tunable_model_family_hypermodel import TunableModelFamilyHypermodel\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T22:18:23.078787Z",
     "start_time": "2024-04-19T22:18:22.902500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from utils.my_tuner import HyperBandSaveLess\n",
    "\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "train, test = dataset_loader((128, 128), is_grayscale=False)\n",
    "\n",
    "dataset_split_controller = KFoldController(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=16, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=16, shuffle=True)\n",
    "\n",
    "model = NaiveDNNTunableModelFamily()\n",
    "hypermodel = TunableModelFamilyHypermodel((3, 128, 128), model)\n",
    "\n",
    "# Adam is too heavy\n",
    "hyperparameters.Fixed(\"optimizer\", \"SGD\")\n",
    "hyperparameters.Fixed(\"layers\", 2)\n",
    "\n",
    "tuner = HyperBandSaveLess(\n",
    "    hypermodel,\n",
    "    hyperparameters=hyperparameters,\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=True,\n",
    "    overwrite=True,\n",
    "    directory=\"dnn-search\",\n",
    "    max_trials=15,\n",
    "    project_name=\"standard_image\"\n",
    ")"
   ],
   "id": "54357f384f26fecd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(256, None), (256, None)]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T22:18:23.081553Z",
     "start_time": "2024-04-19T22:18:23.079542Z"
    }
   },
   "cell_type": "code",
   "source": "tuner.search_space_summary()",
   "id": "69c29613519be4fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "optimizer (Fixed)\n",
      "{'conditions': [], 'value': 'SGD'}\n",
      "layers (Fixed)\n",
      "{'conditions': [], 'value': 2}\n",
      "units_0 (Int)\n",
      "{'default': 256, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 2, 'sampling': 'log'}\n",
      "dropout_0 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "units_1 (Int)\n",
      "{'default': 256, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 2, 'sampling': 'log'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tuner.search(train_dataloader, epochs=2, validation_data=validation_dataloader)",
   "id": "664531c636ca3605",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 01m 24s]\n",
      "val_loss: 0.6720849871635437\n",
      "\n",
      "Best val_loss So Far: 0.6720849871635437\n",
      "Total elapsed time: 00h 01m 24s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "SGD               |SGD               |optimizer\n",
      "2                 |2                 |layers\n",
      "32                |32                |units_0\n",
      "True              |True              |dropout_0\n",
      "64                |32                |units_1\n",
      "\n",
      "[(32, 0.3), (64, None)]\n",
      "Epoch 1/2\n",
      "\u001B[1m 54/237\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m27s\u001B[0m 148ms/step - accuracy: 0.5489 - loss: 0.7532"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_dataloader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001B[0m, in \u001B[0;36mBaseTuner.search\u001B[0;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    231\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_begin(trial)\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_run_and_update_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_end(trial)\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_search_end()\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001B[0m, in \u001B[0;36mBaseTuner._try_run_and_update_trial\u001B[0;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_run_and_update_trial\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs):\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 274\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_and_update_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    275\u001B[0m         trial\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m trial_module\u001B[38;5;241m.\u001B[39mTrialStatus\u001B[38;5;241m.\u001B[39mCOMPLETED\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001B[0m, in \u001B[0;36mBaseTuner._run_and_update_trial\u001B[0;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_and_update_trial\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs):\n\u001B[0;32m--> 239\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mget_trial(trial\u001B[38;5;241m.\u001B[39mtrial_id)\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mexists(\n\u001B[1;32m    241\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mobjective\u001B[38;5;241m.\u001B[39mname\n\u001B[1;32m    242\u001B[0m     ):\n\u001B[1;32m    243\u001B[0m         \u001B[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001B[39;00m\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001B[39;00m\n\u001B[1;32m    245\u001B[0m         \u001B[38;5;66;03m# use case. No further action needed in this case.\u001B[39;00m\n\u001B[1;32m    246\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    247\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe use case of calling \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    248\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    254\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m    255\u001B[0m         )\n",
      "File \u001B[0;32m~/PycharmProjects/muffin-stat-keras/utils/my_tuner.py:11\u001B[0m, in \u001B[0;36mHyperBandSaveLess.run_trial\u001B[0;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[1;32m      9\u001B[0m hp \u001B[38;5;241m=\u001B[39m trial\u001B[38;5;241m.\u001B[39mhyperparameters\n\u001B[1;32m     10\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhypermodel\u001B[38;5;241m.\u001B[39mbuild(hp)\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhypermodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001B[0m, in \u001B[0;36mHyperModel.fit\u001B[0;34m(self, hp, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, hp, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    126\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Train the model.\u001B[39;00m\n\u001B[1;32m    127\u001B[0m \n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;124;03m        If return a float, it should be the `objective` value.\u001B[39;00m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 149\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:118\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/backend/torch/trainer.py:245\u001B[0m, in \u001B[0;36mTorchTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;66;03m# Switch the torch Module to training mode. Inform torch layers to\u001B[39;00m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;66;03m# do training behavior in case the user did not use `self.training`\u001B[39;00m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;66;03m# when implementing a custom layer with torch layers.\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m--> 245\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mepoch_iterator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menumerate_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Callbacks\u001B[39;49;00m\n\u001B[1;32m    247\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_begin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:109\u001B[0m, in \u001B[0;36mEpochIterator.enumerate_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    107\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(buffer) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, buffer\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 109\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msteps_per_execution\u001B[49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torch/utils/data/dataset.py:335\u001B[0m, in \u001B[0;36mConcatDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    334\u001B[0m     sample_idx \u001B[38;5;241m=\u001B[39m idx \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcumulative_sizes[dataset_idx \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m--> 335\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatasets\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdataset_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43msample_idx\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torch/utils/data/dataset.py:391\u001B[0m, in \u001B[0;36mSubset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m idx]]\n\u001B[0;32m--> 391\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torchvision/datasets/folder.py:229\u001B[0m, in \u001B[0;36mDatasetFolder.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;124;03m    index (int): Index\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001B[39;00m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    228\u001B[0m path, target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[index]\n\u001B[0;32m--> 229\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    231\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(sample)\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torchvision/datasets/folder.py:268\u001B[0m, in \u001B[0;36mdefault_loader\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accimage_loader(path)\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpil_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torchvision/datasets/folder.py:248\u001B[0m, in \u001B[0;36mpil_loader\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m    247\u001B[0m     img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(f)\n\u001B[0;32m--> 248\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRGB\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/PIL/Image.py:922\u001B[0m, in \u001B[0;36mImage.convert\u001B[0;34m(self, mode, matrix, dither, palette, colors)\u001B[0m\n\u001B[1;32m    874\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert\u001B[39m(\n\u001B[1;32m    875\u001B[0m     \u001B[38;5;28mself\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, matrix\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dither\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, palette\u001B[38;5;241m=\u001B[39mPalette\u001B[38;5;241m.\u001B[39mWEB, colors\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m\n\u001B[1;32m    876\u001B[0m ):\n\u001B[1;32m    877\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001B[39;00m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;124;03m    method translates pixels through the palette.  If mode is\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    919\u001B[0m \u001B[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001B[39;00m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 922\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    924\u001B[0m     has_transparency \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransparency\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\n\u001B[1;32m    925\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;66;03m# determine default mode\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/PIL/ImageFile.py:291\u001B[0m, in \u001B[0;36mImageFile.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    288\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(msg)\n\u001B[1;32m    290\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[0;32m--> 291\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    293\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## TODO MA PERCHÈ NON VA? SEMBRA ASSOLUTAMENTE NORMALE (256)(1024) ma loss è a 7. Potrebbe essere che ho troppi neuroni al secondo layer?\n",
    "# Sembra di no. Fa schifo per qualche motivo non noto. Indaga poi\n",
    "\n",
    "# PAre funzionare come previsto From the observations better tailor the search space\n",
    "\n",
    "tuner.results_summary()"
   ],
   "id": "a01ca451c64bce38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f80ae010647013e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Results summary\n",
    "Results in dnn-search/standard_image\n",
    "Showing 10 best trials\n",
    "Objective(name=\"val_loss\", direction=\"min\")\n",
    "\n",
    "Trial 08 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 64\n",
    "dropout_0: True\n",
    "units_1: 32\n",
    "Score: 0.606936514377594\n",
    "\n",
    "Trial 14 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 32\n",
    "dropout_0: True\n",
    "units_1: 32\n",
    "Score: 0.6195433735847473\n",
    "\n",
    "Trial 03 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 32\n",
    "dropout_0: False\n",
    "units_1: 1024\n",
    "Score: 0.6893175840377808\n",
    "\n",
    "Trial 07 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 32\n",
    "dropout_0: True\n",
    "units_1: 256\n",
    "Score: 0.6893264651298523\n",
    "\n",
    "Trial 10 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 32\n",
    "dropout_0: True\n",
    "units_1: 128\n",
    "Score: 0.6893460154533386\n",
    "\n",
    "Trial 04 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 512\n",
    "dropout_0: False\n",
    "units_1: 32\n",
    "Score: 7.353879451751709\n",
    "\n",
    "Trial 00 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 256\n",
    "dropout_0: True\n",
    "units_1: 1024\n",
    "Score: 7.353880882263184\n",
    "\n",
    "Trial 06 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 1024\n",
    "dropout_0: True\n",
    "units_1: 1024\n",
    "Score: 7.353880882263184\n",
    "\n",
    "Trial 02 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 256\n",
    "dropout_0: False\n",
    "units_1: 512\n",
    "Score: 7.353881359100342\n",
    "\n",
    "Trial 13 summary\n",
    "Hyperparameters:\n",
    "optimizer: adam\n",
    "layers: 2\n",
    "units_0: 128\n",
    "dropout_0: True\n",
    "units_1: 128\n",
    "Score: 7.3538818359375"
   ],
   "id": "1fbb754cabc50d1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from utils.my_tuner import HyperBandSaveLess\n",
    "\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "train, test = dataset_loader((128, 128), is_grayscale=False)\n",
    "\n",
    "dataset_split_controller = KFoldController(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=16, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=16, shuffle=True)\n",
    "\n",
    "model = NaiveDNNTunableModelFamily()\n",
    "model.hidden_layers = [(32, None), (1024, None)]\n",
    "\n",
    "model_instance =model.make_model((3,128,128))\n",
    "model.compile_model(model_instance, 'adam')\n",
    "model_instance.summary()"
   ],
   "id": "94f0ec737e9d11fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_instance.fit(train_dataloader, epochs=12, validation_data=validation_dataloader)",
   "id": "715e771cb56dff65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Va proprio forte questa configurazione pare. Tienila e studia i possiibli parametri\n",
    "input_layer = keras.Input(shape=(3,128,128), batch_size=16)\n",
    "x = keras.layers.Flatten(data_format=\"channels_first\")(input_layer)\n",
    "x = keras.layers.Dense(units=3500, activation=\"relu\")(x)\n",
    "x = keras.layers.Dense(units=1350, activation=\"relu\")(x)\n",
    "\n",
    "output_layer = keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "id": "4fdbac562396649c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train, test = dataset_loader((128, 128), is_grayscale=False)\n",
    "\n",
    "dataset_split_controller = KFoldController(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=16, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=16, shuffle=True)\n",
    "\n",
    "model.fit(train_dataloader, epochs=12, validation_data=validation_dataloader)"
   ],
   "id": "40b02d24fccbe9de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d618534a7f01607",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
