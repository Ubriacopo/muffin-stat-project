{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-28T14:31:20.147340Z",
     "start_time": "2024-04-28T14:31:20.145308Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# Why Torch? You'll find the answer in the .md files! \n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:31:23.337452Z",
     "start_time": "2024-04-28T14:31:20.641636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset.dataset_loader import dataset_loader\n",
    "import keras_tuner\n",
    "\n",
    "from utils.my_tuner import HistoryDeletingBayesianOptimization\n",
    "\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper"
   ],
   "id": "5250cb61471f3dfe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:31:24.013047Z",
     "start_time": "2024-04-28T14:31:24.009401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "id": "d97b542a2e2f01dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:31:28.963099Z",
     "start_time": "2024-04-28T14:31:28.949402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initial steps\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "train, test = dataset_loader((192, 192), is_grayscale=False)\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=32, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=32, shuffle=True)"
   ],
   "id": "b71c9559544f278e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Steps:\n",
    "\n",
    "- 1: Study the best network inner structure by searching for best hidden nodes structure.\n",
    "- 2: Study the best Hyperparameters for SGD of our top 4 models in general and also the best overfitting one\n",
    "- 3: See top results and try to increase performance by attaching an Augmentation procedure.\n",
    "- 4: See if adding dropout increases the performance of model"
   ],
   "id": "68c4b5bd19508993"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 1:  Study the best network inner structure by searching for best hidden nodes structure\n",
    "\n",
    "  As we need to find the structure of the two layers network. We already saw that 3 layers are harder to train and didn't yield a great performance result.\n",
    "  \n",
    "  We still will try the top 3 models of the 3 layer study with augmentation and dropout to see if performance increases.\n",
    "```py  \n",
    "TwoHiddenLayersTunableAugmentedDNN() # Family we will be tuning\n",
    "```"
   ],
   "id": "7e6726ab371f9839"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:32:02.300127Z",
     "start_time": "2024-04-28T14:32:02.092351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.tunable_model_family_hypermodel import TunableModelFamilyHypermodel\n",
    "from models.naive_dnn_gen.two_layers_dnn import TwoHiddenLayersTunableAugmentedDNN\n",
    "\n",
    "# For now the optimizer is also fixed to SGD with these parameters:\n",
    "hyperparameters.Fixed(\"lr\", 1e-4)\n",
    "hyperparameters.Fixed(\"momentum\", 0.9)\n",
    "\n",
    "# For now dropout layers are frozen to be disabled.\n",
    "hyperparameters.Fixed(\"dropout_0\", False)\n",
    "hyperparameters.Fixed(\"dropout_1\", False)\n",
    "\n",
    "project_name = \"two-layers-192-192\"\n",
    "project_directory = \"dnn-search\"\n",
    "\n",
    "tuner = HistoryDeletingBayesianOptimization(\n",
    "    TunableModelFamilyHypermodel((3, 192, 192), TwoHiddenLayersTunableAugmentedDNN()),\n",
    "    hyperparameters=hyperparameters,\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=True,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=False,\n",
    "    directory=project_directory,\n",
    "    max_trials=15,\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "6781a79d78ea2204",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tuner.search(train_dataloader, epochs=20, validation_data=validation_dataloader, callbacks=[keras.callbacks.CSVLogger(\n",
    "    f\"{project_directory}/{project_name}/search.log\", separator=\",\", append=True)\n",
    "])"
   ],
   "id": "95ad2666aeab06a0",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 16m 36s]\n",
      "\n",
      "Best val_loss So Far: 0.441125825047493\n",
      "Total elapsed time: 02h 03m 55s\n",
      "\n",
      "Search: Running Trial #7\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.0001            |0.0001            |lr\n",
      "0.9               |0.9               |momentum\n",
      "False             |False             |dropout_0\n",
      "False             |False             |dropout_1\n",
      "2560              |1536              |units_0\n",
      "128               |384               |units_1\n",
      "\n",
      "Epoch 1/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 403ms/step - accuracy: 0.5943 - loss: 0.6634 - val_accuracy: 0.6748 - val_loss: 0.6064\n",
      "Epoch 2/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 411ms/step - accuracy: 0.7162 - loss: 0.5685 - val_accuracy: 0.6990 - val_loss: 0.5602\n",
      "Epoch 3/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 372ms/step - accuracy: 0.7525 - loss: 0.5110 - val_accuracy: 0.6959 - val_loss: 0.5950\n",
      "Epoch 4/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 407ms/step - accuracy: 0.7556 - loss: 0.5032 - val_accuracy: 0.7656 - val_loss: 0.4907\n",
      "Epoch 5/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 409ms/step - accuracy: 0.7836 - loss: 0.4744 - val_accuracy: 0.7782 - val_loss: 0.4860\n",
      "Epoch 6/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 363ms/step - accuracy: 0.7862 - loss: 0.4690 - val_accuracy: 0.7149 - val_loss: 0.5479\n",
      "Epoch 7/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 410ms/step - accuracy: 0.7848 - loss: 0.4543 - val_accuracy: 0.7867 - val_loss: 0.4767\n",
      "Epoch 8/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 407ms/step - accuracy: 0.8181 - loss: 0.4213 - val_accuracy: 0.7983 - val_loss: 0.4664\n",
      "Epoch 9/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 404ms/step - accuracy: 0.8421 - loss: 0.3888 - val_accuracy: 0.7899 - val_loss: 0.4605\n",
      "Epoch 10/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 367ms/step - accuracy: 0.8378 - loss: 0.3946 - val_accuracy: 0.7371 - val_loss: 0.5376\n",
      "Epoch 11/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 369ms/step - accuracy: 0.8317 - loss: 0.3855 - val_accuracy: 0.7550 - val_loss: 0.4863\n",
      "Epoch 12/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 409ms/step - accuracy: 0.8527 - loss: 0.3642 - val_accuracy: 0.7930 - val_loss: 0.4486\n",
      "Epoch 13/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 365ms/step - accuracy: 0.8570 - loss: 0.3612 - val_accuracy: 0.7962 - val_loss: 0.4584\n",
      "Epoch 14/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 368ms/step - accuracy: 0.8545 - loss: 0.3616 - val_accuracy: 0.7751 - val_loss: 0.4816\n",
      "Epoch 15/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 367ms/step - accuracy: 0.8623 - loss: 0.3537 - val_accuracy: 0.6948 - val_loss: 0.6192\n",
      "Epoch 16/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 369ms/step - accuracy: 0.8594 - loss: 0.3519 - val_accuracy: 0.7709 - val_loss: 0.4720\n",
      "Epoch 17/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 365ms/step - accuracy: 0.8720 - loss: 0.3263 - val_accuracy: 0.7941 - val_loss: 0.4600\n",
      "Epoch 18/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 413ms/step - accuracy: 0.8788 - loss: 0.3159 - val_accuracy: 0.7962 - val_loss: 0.4468\n",
      "Epoch 19/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 369ms/step - accuracy: 0.8879 - loss: 0.3078 - val_accuracy: 0.7529 - val_loss: 0.5042\n",
      "Epoch 20/20\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 371ms/step - accuracy: 0.8885 - loss: 0.3020 - val_accuracy: 0.7825 - val_loss: 0.4494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/PycharmProjects/muffin-stat-project/utils/my_tuner.py\", line 20, in run_trial\n",
      "    return super().run_trial(trial, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 232, in _build_and_fit_model\n",
      "    model = self._try_build(hp)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 164, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 155, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 120, in _build_wrapper\n",
      "    return self._build(hp, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/PycharmProjects/muffin-stat-project/models/structure/tunable_model_family_hypermodel.py\", line 34, in build\n",
      "    model = self.model_family.make_model(self.input_shape)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/PycharmProjects/muffin-stat-project/models/structure/base_model_family.py\", line 38, in make_model\n",
      "    def make_model(self, input_shape: (int, int, int)) -> keras.Model:\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/PycharmProjects/muffin-stat-project/models/naive_dnn_gen/two_layers_dnn.py\", line 26, in make_layers\n",
      "    x = keras.layers.Dense(units=self.hidden_layer_0.units, activation=\"relu\")(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 123, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/backend/torch/random.py\", line 82, in uniform\n",
      "    output = (maxval - minval) * rand_tensor + minval\n",
      "             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 7.75 GiB of which 620.69 MiB is free. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Of the allocated memory 5.29 GiB is allocated by PyTorch, and 629.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/PycharmProjects/muffin-stat-project/utils/my_tuner.py\", line 20, in run_trial\n    return super().run_trial(trial, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 232, in _build_and_fit_model\n    model = self._try_build(hp)\n            ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 164, in _try_build\n    model = self._build_hypermodel(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 155, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 120, in _build_wrapper\n    return self._build(hp, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/PycharmProjects/muffin-stat-project/models/structure/tunable_model_family_hypermodel.py\", line 34, in build\n    model = self.model_family.make_model(self.input_shape)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/PycharmProjects/muffin-stat-project/models/structure/base_model_family.py\", line 38, in make_model\n    def make_model(self, input_shape: (int, int, int)) -> keras.Model:\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/PycharmProjects/muffin-stat-project/models/naive_dnn_gen/two_layers_dnn.py\", line 26, in make_layers\n    x = keras.layers.Dense(units=self.hidden_layer_0.units, activation=\"relu\")(x)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 123, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/backend/torch/random.py\", line 82, in uniform\n    output = (maxval - minval) * rand_tensor + minval\n             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 7.75 GiB of which 620.69 MiB is free. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Of the allocated memory 5.29 GiB is allocated by PyTorch, and 629.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCSVLogger\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mproject_directory\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mproject_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/search.log\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseparator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mappend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:235\u001B[0m, in \u001B[0;36mBaseTuner.search\u001B[0;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_begin(trial)\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_run_and_update_trial(trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs)\n\u001B[0;32m--> 235\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_trial_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_search_end()\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:339\u001B[0m, in \u001B[0;36mBaseTuner.on_trial_end\u001B[0;34m(self, trial)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_trial_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial):\n\u001B[1;32m    334\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Called at the end of a trial.\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;124;03m        trial: A `Trial` instance.\u001B[39;00m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 339\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moracle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave()\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:108\u001B[0m, in \u001B[0;36msynchronized.<locals>.wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    106\u001B[0m     LOCKS[oracle]\u001B[38;5;241m.\u001B[39macquire()\n\u001B[1;32m    107\u001B[0m     THREADS[oracle] \u001B[38;5;241m=\u001B[39m thread_name\n\u001B[0;32m--> 108\u001B[0m ret_val \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m need_acquire:\n\u001B[1;32m    110\u001B[0m     THREADS[oracle] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:588\u001B[0m, in \u001B[0;36mOracle.end_trial\u001B[0;34m(self, trial)\u001B[0m\n\u001B[1;32m    586\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry(trial):\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mend_order\u001B[38;5;241m.\u001B[39mappend(trial\u001B[38;5;241m.\u001B[39mtrial_id)\n\u001B[0;32m--> 588\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_consecutive_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    590\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_trial(trial)\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave()\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:545\u001B[0m, in \u001B[0;36mOracle._check_consecutive_failures\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    543\u001B[0m     consecutive_failures \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    544\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m consecutive_failures \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_consecutive_failed_trials:\n\u001B[0;32m--> 545\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    546\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of consecutive failures exceeded the limit \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    547\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_consecutive_failed_trials\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    548\u001B[0m         \u001B[38;5;241m+\u001B[39m (trial\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    549\u001B[0m     )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/PycharmProjects/muffin-stat-project/utils/my_tuner.py\", line 20, in run_trial\n    return super().run_trial(trial, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 232, in _build_and_fit_model\n    model = self._try_build(hp)\n            ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 164, in _try_build\n    model = self._build_hypermodel(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 155, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 120, in _build_wrapper\n    return self._build(hp, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/PycharmProjects/muffin-stat-project/models/structure/tunable_model_family_hypermodel.py\", line 34, in build\n    model = self.model_family.make_model(self.input_shape)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/PycharmProjects/muffin-stat-project/models/structure/base_model_family.py\", line 38, in make_model\n    def make_model(self, input_shape: (int, int, int)) -> keras.Model:\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/PycharmProjects/muffin-stat-project/models/naive_dnn_gen/two_layers_dnn.py\", line 26, in make_layers\n    x = keras.layers.Dense(units=self.hidden_layer_0.units, activation=\"relu\")(x)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 123, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/backend/torch/random.py\", line 82, in uniform\n    output = (maxval - minval) * rand_tensor + minval\n             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 7.75 GiB of which 620.69 MiB is free. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Of the allocated memory 5.29 GiB is allocated by PyTorch, and 629.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T10:24:56.723153Z",
     "start_time": "2024-04-28T10:24:56.673955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.base_model_family import HiddenLayerStructure\n",
    "from models.naive_dnn_gen.two_layers_dnn import TwoHiddenLayersDNNAugModelFamily\n",
    "\n",
    "family_gen = TwoHiddenLayersDNNAugModelFamily()\n",
    "family_gen.hidden_layer_0 = HiddenLayerStructure(2718, None)\n",
    "family_gen.hidden_layer_1 = HiddenLayerStructure(728, None)\n",
    "\n",
    "model = family_gen.make_model((3, 192, 192))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9, nesterov=True), metrics=['accuracy'])\n",
    "\n",
    "model.summary(expand_nested=True)"
   ],
   "id": "3cb1bee188676a2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_17\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ AugmentedDNN (\u001B[38;5;33mInputLayer\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m192\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_13 (\u001B[38;5;33mFunctional\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m3\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ AugmentedDNN (\u001B[38;5;33mInputLayer\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m192\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ permute_2 (\u001B[38;5;33mPermute\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m3\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ random_contrast_2          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m3\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mRandomContrast\u001B[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ random_flip_2 (\u001B[38;5;33mRandomFlip\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m3\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_15 (\u001B[38;5;33mFunctional\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │   \u001B[38;5;34m302,571,935\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ AugmentedDNN (\u001B[38;5;33mInputLayer\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m192\u001B[0m, \u001B[38;5;34m3\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ flatten_2 (\u001B[38;5;33mFlatten\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m110592\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (\u001B[38;5;33mDense\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2718\u001B[0m)           │   \u001B[38;5;34m300,591,774\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (\u001B[38;5;33mDense\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m728\u001B[0m)            │     \u001B[38;5;34m1,979,432\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_8 (\u001B[38;5;33mDense\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m729\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ AugmentedDNN (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ AugmentedDNN (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ permute_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ random_contrast_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomContrast</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ random_flip_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │   <span style=\"color: #00af00; text-decoration-color: #00af00\">302,571,935</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ AugmentedDNN (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110592</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2718</span>)           │   <span style=\"color: #00af00; text-decoration-color: #00af00\">300,591,774</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">728</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,979,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│    └ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">729</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m302,571,935\u001B[0m (1.13 GB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">302,571,935</span> (1.13 GB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m302,571,935\u001B[0m (1.13 GB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">302,571,935</span> (1.13 GB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:21:46.764474Z",
     "start_time": "2024-04-28T10:24:57.496500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(train_dataloader, validation_data=validation_dataloader, epochs=150,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(\n",
    "                        monitor='val_loss', min_delta=1e-4, patience=20, verbose=1, mode='min',\n",
    "                        restore_best_weights=True\n",
    "                    )])"
   ],
   "id": "d6cd1def9ca56e61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 394ms/step - accuracy: 0.5857 - loss: 0.6649 - val_accuracy: 0.7159 - val_loss: 0.5835\n",
      "Epoch 2/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 384ms/step - accuracy: 0.7110 - loss: 0.5601 - val_accuracy: 0.6874 - val_loss: 0.5902\n",
      "Epoch 3/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.7229 - loss: 0.5400 - val_accuracy: 0.6737 - val_loss: 0.6034\n",
      "Epoch 4/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 389ms/step - accuracy: 0.7474 - loss: 0.5288 - val_accuracy: 0.7497 - val_loss: 0.5147\n",
      "Epoch 5/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 391ms/step - accuracy: 0.7579 - loss: 0.5108 - val_accuracy: 0.7878 - val_loss: 0.4904\n",
      "Epoch 6/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 395ms/step - accuracy: 0.7683 - loss: 0.4891 - val_accuracy: 0.8025 - val_loss: 0.4724\n",
      "Epoch 7/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.7711 - loss: 0.4825 - val_accuracy: 0.7677 - val_loss: 0.4916\n",
      "Epoch 8/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 384ms/step - accuracy: 0.7668 - loss: 0.4813 - val_accuracy: 0.7645 - val_loss: 0.5068\n",
      "Epoch 9/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 384ms/step - accuracy: 0.7732 - loss: 0.4875 - val_accuracy: 0.7835 - val_loss: 0.4746\n",
      "Epoch 10/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 394ms/step - accuracy: 0.7837 - loss: 0.4761 - val_accuracy: 0.7899 - val_loss: 0.4675\n",
      "Epoch 11/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 388ms/step - accuracy: 0.7833 - loss: 0.4577 - val_accuracy: 0.7371 - val_loss: 0.5121\n",
      "Epoch 12/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 383ms/step - accuracy: 0.7956 - loss: 0.4552 - val_accuracy: 0.7782 - val_loss: 0.4782\n",
      "Epoch 13/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 388ms/step - accuracy: 0.7941 - loss: 0.4429 - val_accuracy: 0.7529 - val_loss: 0.4925\n",
      "Epoch 14/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 390ms/step - accuracy: 0.8009 - loss: 0.4511 - val_accuracy: 0.7677 - val_loss: 0.4942\n",
      "Epoch 15/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 388ms/step - accuracy: 0.8142 - loss: 0.4223 - val_accuracy: 0.7867 - val_loss: 0.4674\n",
      "Epoch 16/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 399ms/step - accuracy: 0.7999 - loss: 0.4458 - val_accuracy: 0.7973 - val_loss: 0.4624\n",
      "Epoch 17/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8153 - loss: 0.4195 - val_accuracy: 0.7677 - val_loss: 0.4855\n",
      "Epoch 18/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.8089 - loss: 0.4325 - val_accuracy: 0.7540 - val_loss: 0.4916\n",
      "Epoch 19/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 396ms/step - accuracy: 0.8191 - loss: 0.4270 - val_accuracy: 0.8004 - val_loss: 0.4529\n",
      "Epoch 20/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 393ms/step - accuracy: 0.8234 - loss: 0.4169 - val_accuracy: 0.8152 - val_loss: 0.4454\n",
      "Epoch 21/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8323 - loss: 0.4143 - val_accuracy: 0.8046 - val_loss: 0.4465\n",
      "Epoch 22/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 393ms/step - accuracy: 0.8317 - loss: 0.4147 - val_accuracy: 0.8184 - val_loss: 0.4344\n",
      "Epoch 23/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8275 - loss: 0.4158 - val_accuracy: 0.8046 - val_loss: 0.4487\n",
      "Epoch 24/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.8244 - loss: 0.4111 - val_accuracy: 0.7297 - val_loss: 0.5450\n",
      "Epoch 25/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8159 - loss: 0.4204 - val_accuracy: 0.7371 - val_loss: 0.5112\n",
      "Epoch 26/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 384ms/step - accuracy: 0.8308 - loss: 0.4118 - val_accuracy: 0.7635 - val_loss: 0.4748\n",
      "Epoch 27/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 390ms/step - accuracy: 0.8321 - loss: 0.4053 - val_accuracy: 0.7888 - val_loss: 0.4606\n",
      "Epoch 28/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8388 - loss: 0.3935 - val_accuracy: 0.8120 - val_loss: 0.4392\n",
      "Epoch 29/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8259 - loss: 0.3999 - val_accuracy: 0.7413 - val_loss: 0.5214\n",
      "Epoch 30/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 394ms/step - accuracy: 0.8199 - loss: 0.4012 - val_accuracy: 0.8226 - val_loss: 0.4296\n",
      "Epoch 31/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 382ms/step - accuracy: 0.8415 - loss: 0.3888 - val_accuracy: 0.8089 - val_loss: 0.4411\n",
      "Epoch 32/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8437 - loss: 0.3679 - val_accuracy: 0.7592 - val_loss: 0.4906\n",
      "Epoch 33/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 394ms/step - accuracy: 0.8479 - loss: 0.3820 - val_accuracy: 0.8237 - val_loss: 0.4219\n",
      "Epoch 34/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.8394 - loss: 0.3890 - val_accuracy: 0.8173 - val_loss: 0.4275\n",
      "Epoch 35/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.8488 - loss: 0.3632 - val_accuracy: 0.7867 - val_loss: 0.4458\n",
      "Epoch 36/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8545 - loss: 0.3718 - val_accuracy: 0.7582 - val_loss: 0.4859\n",
      "Epoch 37/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 395ms/step - accuracy: 0.8472 - loss: 0.3618 - val_accuracy: 0.8363 - val_loss: 0.4145\n",
      "Epoch 38/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 388ms/step - accuracy: 0.8532 - loss: 0.3728 - val_accuracy: 0.7888 - val_loss: 0.4524\n",
      "Epoch 39/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.8408 - loss: 0.3746 - val_accuracy: 0.7350 - val_loss: 0.5241\n",
      "Epoch 40/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 381ms/step - accuracy: 0.8487 - loss: 0.3592 - val_accuracy: 0.7698 - val_loss: 0.4803\n",
      "Epoch 41/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.8516 - loss: 0.3501 - val_accuracy: 0.8205 - val_loss: 0.4340\n",
      "Epoch 42/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 384ms/step - accuracy: 0.8657 - loss: 0.3473 - val_accuracy: 0.7402 - val_loss: 0.5175\n",
      "Epoch 43/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 383ms/step - accuracy: 0.8588 - loss: 0.3477 - val_accuracy: 0.8057 - val_loss: 0.4330\n",
      "Epoch 44/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 393ms/step - accuracy: 0.8598 - loss: 0.3506 - val_accuracy: 0.8289 - val_loss: 0.4096\n",
      "Epoch 45/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8583 - loss: 0.3509 - val_accuracy: 0.7962 - val_loss: 0.4534\n",
      "Epoch 46/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8661 - loss: 0.3360 - val_accuracy: 0.7181 - val_loss: 0.5581\n",
      "Epoch 47/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8546 - loss: 0.3500 - val_accuracy: 0.8110 - val_loss: 0.4362\n",
      "Epoch 48/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.8619 - loss: 0.3329 - val_accuracy: 0.8152 - val_loss: 0.4194\n",
      "Epoch 49/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 388ms/step - accuracy: 0.8643 - loss: 0.3369 - val_accuracy: 0.8163 - val_loss: 0.4181\n",
      "Epoch 50/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8774 - loss: 0.3172 - val_accuracy: 0.8152 - val_loss: 0.4382\n",
      "Epoch 51/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 389ms/step - accuracy: 0.8880 - loss: 0.3020 - val_accuracy: 0.7920 - val_loss: 0.4382\n",
      "Epoch 52/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 398ms/step - accuracy: 0.8804 - loss: 0.3160 - val_accuracy: 0.8353 - val_loss: 0.4066\n",
      "Epoch 53/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 384ms/step - accuracy: 0.8786 - loss: 0.3133 - val_accuracy: 0.7983 - val_loss: 0.4285\n",
      "Epoch 54/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 392ms/step - accuracy: 0.8745 - loss: 0.3102 - val_accuracy: 0.8490 - val_loss: 0.3974\n",
      "Epoch 55/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8742 - loss: 0.3207 - val_accuracy: 0.7529 - val_loss: 0.5207\n",
      "Epoch 56/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 381ms/step - accuracy: 0.8795 - loss: 0.3074 - val_accuracy: 0.7920 - val_loss: 0.4447\n",
      "Epoch 57/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.8887 - loss: 0.3101 - val_accuracy: 0.8332 - val_loss: 0.4044\n",
      "Epoch 58/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8797 - loss: 0.3101 - val_accuracy: 0.8004 - val_loss: 0.4278\n",
      "Epoch 59/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8772 - loss: 0.3023 - val_accuracy: 0.7804 - val_loss: 0.4744\n",
      "Epoch 60/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8804 - loss: 0.2973 - val_accuracy: 0.7835 - val_loss: 0.4438\n",
      "Epoch 61/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8850 - loss: 0.2983 - val_accuracy: 0.7825 - val_loss: 0.4567\n",
      "Epoch 62/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 384ms/step - accuracy: 0.8894 - loss: 0.2849 - val_accuracy: 0.7973 - val_loss: 0.4558\n",
      "Epoch 63/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8805 - loss: 0.2966 - val_accuracy: 0.7719 - val_loss: 0.4631\n",
      "Epoch 64/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8856 - loss: 0.2915 - val_accuracy: 0.7994 - val_loss: 0.4259\n",
      "Epoch 65/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.9032 - loss: 0.2718 - val_accuracy: 0.7677 - val_loss: 0.4852\n",
      "Epoch 66/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.8897 - loss: 0.2921 - val_accuracy: 0.8226 - val_loss: 0.4194\n",
      "Epoch 67/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 388ms/step - accuracy: 0.8983 - loss: 0.2790 - val_accuracy: 0.7297 - val_loss: 0.5589\n",
      "Epoch 68/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 385ms/step - accuracy: 0.8925 - loss: 0.2824 - val_accuracy: 0.8068 - val_loss: 0.4226\n",
      "Epoch 69/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 389ms/step - accuracy: 0.8973 - loss: 0.2730 - val_accuracy: 0.8226 - val_loss: 0.4138\n",
      "Epoch 70/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 388ms/step - accuracy: 0.9072 - loss: 0.2611 - val_accuracy: 0.8152 - val_loss: 0.4174\n",
      "Epoch 71/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 386ms/step - accuracy: 0.9034 - loss: 0.2733 - val_accuracy: 0.7930 - val_loss: 0.4370\n",
      "Epoch 72/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 388ms/step - accuracy: 0.8954 - loss: 0.2734 - val_accuracy: 0.7930 - val_loss: 0.4304\n",
      "Epoch 73/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 388ms/step - accuracy: 0.9060 - loss: 0.2585 - val_accuracy: 0.7518 - val_loss: 0.5277\n",
      "Epoch 74/150\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 387ms/step - accuracy: 0.8882 - loss: 0.2777 - val_accuracy: 0.8247 - val_loss: 0.4099\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 54.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b4943fa444d524dc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
