{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:17:45.175289Z",
     "start_time": "2024-05-01T15:17:43.115679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset.dataset_loader import dataset_loader\n",
    "import keras_tuner\n",
    "\n",
    "from utils.my_tuner import HistoryDeletingBayesianOptimization\n",
    "\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper\n",
    "from models.naive_dnn_gen.two_layers_dnn import TwoHiddenLayersTunableAugmentedDNN, TwoHiddenLayersDNNAugModelFamily\n",
    "from models.structure.base_model_family import HiddenLayerStructure"
   ],
   "id": "5250cb61471f3dfe",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "# Why Torch? You'll find the answer in the .md files! \n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ],
   "id": "initial_id",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:17:45.179236Z",
     "start_time": "2024-05-01T15:17:45.176043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "id": "d97b542a2e2f01dc",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:17:45.195122Z",
     "start_time": "2024-05-01T15:17:45.179744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initial steps\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "train, test = dataset_loader((192, 192), is_grayscale=False)\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=32, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=32, shuffle=True)"
   ],
   "id": "b71c9559544f278e",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Steps:\n",
    "\n",
    "- 1: Study the best network inner structure by searching for best hidden nodes structure.\n",
    "- 2: Study the best Hyperparameters for SGD of our top 4 models in general and also the best overfitting one\n",
    "- 3: See top results and try to increase performance by attaching an Augmentation procedure.\n",
    "- 4: See if adding dropout increases the performance of model"
   ],
   "id": "68c4b5bd19508993"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 1:  Study the best network inner structure by searching for best hidden nodes structure\n",
    "\n",
    "  As we need to find the structure of the two layers network. We already saw that 3 layers are harder to train and didn't yield a great performance result.\n",
    "  \n",
    "  We still will try the top 3 models of the 3 layer study with augmentation and dropout to see if performance increases.\n",
    "```py  \n",
    "TwoHiddenLayersTunableAugmentedDNN() # Family we will be tuning\n",
    "```"
   ],
   "id": "7e6726ab371f9839"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:17:45.769260Z",
     "start_time": "2024-05-01T15:17:45.680521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.tunable_model_family_hypermodel import TunableModelFamilyHypermodel\n",
    "from models.naive_dnn_gen.two_layers_dnn import TwoHiddenLayersTunableAugmentedDNN\n",
    "\n",
    "# For now the optimizer is also fixed to SGD with these parameters:\n",
    "hyperparameters.Fixed(\"lr\", 1e-4)\n",
    "hyperparameters.Fixed(\"momentum\", 0.9)\n",
    "\n",
    "# For now dropout layers are frozen to be disabled.\n",
    "hyperparameters.Fixed(\"dropout_0\", False)\n",
    "hyperparameters.Fixed(\"dropout_1\", False)\n",
    "\n",
    "project_name = \"two-layers-192-192\"\n",
    "project_directory = \"dnn-search\"\n",
    "\n",
    "tuner = HistoryDeletingBayesianOptimization(\n",
    "    TunableModelFamilyHypermodel((3, 192, 192), TwoHiddenLayersTunableAugmentedDNN()),\n",
    "    hyperparameters=hyperparameters,\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=True,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory=project_directory,\n",
    "    max_trials=15,\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "6781a79d78ea2204",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_has_been_done = True  # To avoid overriding my stuff.\n",
    "if not search_has_been_done:\n",
    "    tuner.search(train_dataloader, epochs=20, validation_data=validation_dataloader,\n",
    "                 callbacks=[keras.callbacks.CSVLogger(\n",
    "                     f\"{project_directory}/{project_name}/search.log\", separator=\",\", append=True)\n",
    "                 ])"
   ],
   "id": "95ad2666aeab06a0",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:07:08.007692Z",
     "start_time": "2024-05-01T08:07:08.005134Z"
    }
   },
   "cell_type": "code",
   "source": "tuner.results_summary(5)",
   "id": "14970775a921510b",
   "execution_count": 54,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:15:41.825233Z",
     "start_time": "2024-05-01T15:15:41.811150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas\n",
    "\n",
    "csv = pandas.read_csv(\"./dnn-search/two-layers-192-192/search.log\")\n",
    "csv['tuner_iteration'] = 0\n",
    "\n",
    "current_iteration = 0\n",
    "for index, row in enumerate(csv.itertuples()):\n",
    "    csv.at[index, 'tuner_iteration'] = int(index / 20)\n",
    "\n",
    "best_dataframe = csv.query(\"tuner_iteration in [10, 12, 14, 7, 8]\")\n",
    "best_overfitting = csv.query(\"tuner iteration in [0]\")"
   ],
   "id": "d3991245f9a14f44",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:15:42.541424Z",
     "start_time": "2024-05-01T15:15:42.210291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "px.line(best_dataframe, x=\"epoch\", y=[\"loss\", \"val_loss\"], color=\"tuner_iteration\", template=\"plotly_white\",\n",
    "        markers=True)"
   ],
   "id": "daeb66b8fffca21f",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_figure = px.line(best_dataframe, x=\"epoch\", y=[\"loss\"], color=\"tuner_iteration\", template=\"plotly_white\",\n",
    "                      markers=True)\n",
    "loss_figure.update_layout(title=\"Loss in tuner search\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")"
   ],
   "id": "9003acb4dbc58145",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:15:42.932891Z",
     "start_time": "2024-05-01T15:15:42.902459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figure = px.line(best_dataframe, x=\"epoch\", y=[\"val_loss\"], color=\"tuner_iteration\", template=\"plotly_white\",\n",
    "                 markers=True)\n",
    "figure.update_layout(title=\"Validation Loss in tuner search\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")"
   ],
   "id": "a377ad05410e6cb0",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How can we increase the performance of the 5 best models? We select 2 models to perform the following improvements:\n",
    " - 1 -Augmentation of the dataset\n",
    "- 2 - Dropout layers inside the network\n",
    " - 3 -Better tune hyperparameters related to the learning process and not network structure (SGD)\n",
    "\n",
    "### What models should we pick?\n",
    "Should we only look the loss? As I see it a nice idea could to take the best overall model we generated, the best that has lowest variance in the val loss (least amount of spikes) (10) (riformula come si deve) and the best overfitting model (which might become a good model with augmentation). Therefore we pick:\n",
    "- 10 (Compared to 8 and 12 it has less spikes and generally performs beter than 8 and 14) (Which also is best of search)\n",
    "- 12 (As it is the best in training loss, our procedure might make it a good model)\n",
    "- 7 (It performs well enough compared to the others and is the least complex network)"
   ],
   "id": "ddf6fda59a7ec2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:17:54.461368Z",
     "start_time": "2024-05-01T15:17:54.458265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_hyperparameters_references = [\n",
    "    dict(iteration=14, hyperparameters_index=0),\n",
    "    dict(iteration=12, hyperparameters_index=1),\n",
    "    dict(iteration=7, hyperparameters_index=3),\n",
    "]\n",
    "\n",
    "[print(f\"iteration:{i['iteration']}, hp: {tuner.get_best_hyperparameters(5)[i['hyperparameters_index']].values}\") for i\n",
    " in best_hyperparameters_references]"
   ],
   "id": "a9c90bc1606b3868",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 - Augmentation of the dataset",
   "id": "1719adf27b75e9e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:47:59.355039Z",
     "start_time": "2024-05-01T12:47:59.329005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For Iteration 10.\n",
    "current_hyperparameters = tuner.get_best_hyperparameters(5)[best_hyperparameters_references[0]['hyperparameters_index']]\n",
    "aug_model_family = TwoHiddenLayersDNNAugModelFamily()\n",
    "\n",
    "# This section could be made a function as it is always the same.\n",
    "# Dropout will be done in the next steps. So for now it is None.\n",
    "aug_model_family.hidden_layer_0 = HiddenLayerStructure(units=current_hyperparameters['units_0'], following_dropout=None)\n",
    "aug_model_family.hidden_layer_1 = HiddenLayerStructure(units=current_hyperparameters['units_1'], following_dropout=None)\n",
    "\n",
    "current_model = aug_model_family.make_model((3, 192, 192))\n",
    "current_model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"],\n",
    "                      optimizer=keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9, nesterov=True))\n",
    "current_model.summary(expand_nested=True)"
   ],
   "id": "584ae798096a5783",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T13:47:17.786320Z",
     "start_time": "2024-05-01T12:52:08.626846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Should I already use K-fold CV? It would take forever\n",
    "history = current_model.fit(train_dataloader, validation_data=validation_dataloader, epochs=150,\n",
    "                            callbacks=[\n",
    "                                # To avoid going further when training\n",
    "                                keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss', min_delta=1e-4, patience=10,\n",
    "                                    verbose=1, mode='min', restore_best_weights=True\n",
    "                                ),\n",
    "                                # To persist the history\n",
    "                                keras.callbacks.CSVLogger(\n",
    "                                    f\"{project_directory}/{project_name}/model{best_hyperparameters_references[0]['iteration']}-aug.log\",\n",
    "                                    separator=\",\", append=True\n",
    "                                )\n",
    "                            ])"
   ],
   "id": "5fdf5ff9149e3045",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Validation loss has not decreased. Augmentation not enough? ",
   "id": "b4943fa444d524dc",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:18:00.784469Z",
     "start_time": "2024-05-01T15:18:00.717715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For Iteration 10.\n",
    "current_hyperparameters = tuner.get_best_hyperparameters(5)[best_hyperparameters_references[1]['hyperparameters_index']]\n",
    "aug_model_family = TwoHiddenLayersDNNAugModelFamily()\n",
    "\n",
    "# This section could be made a function as it is always the same.\n",
    "# Dropout will be done in the next steps. So for now it is None.\n",
    "aug_model_family.hidden_layer_0 = HiddenLayerStructure(units=current_hyperparameters['units_0'], following_dropout=None)\n",
    "aug_model_family.hidden_layer_1 = HiddenLayerStructure(units=current_hyperparameters['units_1'], following_dropout=None)\n",
    "\n",
    "current_model = aug_model_family.make_model((3, 192, 192))\n",
    "current_model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"],\n",
    "                      optimizer=keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9, nesterov=True))\n",
    "current_model.summary(expand_nested=True)"
   ],
   "id": "a4b157b803f8c86b",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T15:18:02.944738Z",
     "start_time": "2024-05-01T15:18:02.137577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Should I already use K-fold CV? It would take forever\n",
    "history = current_model.fit(train_dataloader, validation_data=validation_dataloader, epochs=150,\n",
    "                            callbacks=[\n",
    "                                # To avoid going further when training\n",
    "                                keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss', min_delta=1e-4, patience=10,\n",
    "                                    verbose=1, mode='min', restore_best_weights=True\n",
    "                                ),\n",
    "                                # To persist the history\n",
    "                                keras.callbacks.CSVLogger(\n",
    "                                    f\"{project_directory}/{project_name}/model{best_hyperparameters_references[1]['iteration']}-aug.log\",\n",
    "                                    separator=\",\", append=True\n",
    "                                )\n",
    "                            ])"
   ],
   "id": "11f9799de71050b",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "37e915841902e3dc",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
