{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Non si capisce niente. Risistema il file",
   "id": "1da71b9c6ef7ac36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import keras\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from keras_tuner import HyperParameters\n",
    "from dataset.dataset_loader import dataset_loader\n",
    "import keras_tuner\n",
    "\n",
    "from utils.my_tuner import HistoryDeletingBayesianOptimization\n",
    "from models.structure.tunable_hypermodel import TunableHyperModel\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper\n",
    "import torch"
   ],
   "id": "2ed5d61161541b73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initial steps\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "train, test = dataset_loader((224, 224), is_grayscale=False)\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=32, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=32, shuffle=True)"
   ],
   "id": "618119537f575ca8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# HyperTuning and search\n",
    "Ho fissato il numero di layer ma vorrei renderlo libero"
   ],
   "id": "d81b31c376157493"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.structure.learning_parameters.sgd_learning_parameters import SgdLearningParametersTunable\n",
    "from models.simple_cnn.conv_net_family import TunableConvNetFamily\n",
    "from models.structure.tunable_hypermodel import TunableHyperModel\n",
    "\n",
    "# For now the optimizer is also fixed to SGD with these parameters:\n",
    "hyperparameters.Fixed(\"lr\", 1e-4)\n",
    "hyperparameters.Fixed(\"momentum\", 0.9)\n",
    "\n",
    "# For now dropout layers are frozen to be disabled.\n",
    "hyperparameters.Fixed(\"dropout_0\", False)\n",
    "\n",
    "project_name = \"multi-layers\"\n",
    "project_directory = \"cnn_search\"\n",
    "\n",
    "tuner = HistoryDeletingBayesianOptimization(\n",
    "    TunableHyperModel(TunableConvNetFamily(), SgdLearningParametersTunable(1e-4), (3, 224, 224)),\n",
    "    hyperparameters=hyperparameters,\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=True,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory=project_directory,\n",
    "    max_trials=15,\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "1f33aefb59c0828a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Proviamo con random tuner e riduciamo la batch size da 32 a 16\n",
    "Il Random tuner con totale di 60 iterazioni come suggerito da: https://web.archive.org/web/20160701182750/http://blog.dato.com/how-to-evaluate-machine-learning-models-part-4-hyperparameter-tuning"
   ],
   "id": "2f5c7c67472cc0eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initial steps\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "train, test = dataset_loader((224, 224), is_grayscale=False)\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=16, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=16, shuffle=True)"
   ],
   "id": "3dcdf96fe8cdb732",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For now the optimizer is also fixed to SGD with these parameters:\n",
    "hyperparameters.Fixed(\"lr\", 1e-4)\n",
    "hyperparameters.Fixed(\"momentum\", 0.9)\n",
    "\n",
    "hyperparameters.Int(f\"filters_0\", min_value=16, max_value=256, step=2, sampling='log')\n",
    "hyperparameters.Int(f\"filters_1\", min_value=16, max_value=256, step=2, sampling='log')\n",
    "hyperparameters.Int(f\"filters_2\", min_value=16, max_value=256, step=2, sampling='log')\n",
    "hyperparameters.Int(f\"filters_3\", min_value=16, max_value=256, step=2, sampling='log')\n",
    "\n",
    "hyperparameters.Choice(f\"kernel_0\", values=[3, 5], default=3)\n",
    "hyperparameters.Choice(f\"kernel_1\", values=[3, 5], default=3)\n",
    "hyperparameters.Choice(f\"kernel_2\", values=[3, 5], default=3)\n",
    "hyperparameters.Choice(f\"kernel_3\", values=[3, 5], default=3)\n",
    "\n",
    "hyperparameters.Int(name=f\"units_0\", min_value=32, max_value=256, step=2, sampling='log')\n",
    "hyperparameters.Int(name=f\"units_1\", min_value=32, max_value=256, step=2, sampling='log')\n",
    "hyperparameters.Int(name=f\"units_2\", min_value=32, max_value=256, step=2, sampling='log')\n",
    "\n",
    "# For now dropout layers are frozen to be disabled.\n",
    "hyperparameters.Fixed(\"dropout_0\", False)\n",
    "hyperparameters.Fixed(\"dropout_1\", False)\n",
    "hyperparameters.Fixed(\"dropout_2\", False)\n",
    "\n"
   ],
   "id": "41b8013b9d1cb63d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.my_tuner import HistoryDeletingRandomSearch\n",
    "from models.simple_cnn.conv_net_family import TunableConvNetFamily\n",
    "from models.structure.learning_parameters.sgd_learning_parameters import SgdLearningParametersTunable\n",
    "project_name = \"random-search-rich-structure\"\n",
    "directory = \"cnn_search\"\n",
    "\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "tuner = HistoryDeletingRandomSearch(\n",
    "    TunableHyperModel(TunableConvNetFamily(), SgdLearningParametersTunable(learning_rate=1e-4), (3, 224, 224)),\n",
    "    hyperparameters=hyperparameters,\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=True,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory=directory,\n",
    "    max_trials=60,\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "5a44301582967f8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import callbacks.threshold_stop_cb\n",
    "\n",
    "search_has_been_done = True  # To avoid overriding my stuff.\n",
    "if not search_has_been_done:\n",
    "    tuner.search(train_dataloader, epochs=12, validation_data=validation_dataloader,\n",
    "                 callbacks=[\n",
    "                     keras.callbacks.CSVLogger(f\"{directory}/{project_name}/search.log\", separator=\",\", append=True),\n",
    "                     callbacks.threshold_stop_cb.ThresholdStopCallback(0.5, 4),\n",
    "                 ])"
   ],
   "id": "969d11aa38dbe647",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Trial 1  was skipper for unknown reasons",
   "id": "ea056114fd6189bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tuner.results_summary(5)",
   "id": "cd75229c3d73b1b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas\n",
    "\n",
    "csv = pandas.read_csv(f\"./cnn_search/{project_name}/search.log\")\n",
    "csv['tuner_iteration'] = 0\n",
    "\n",
    "current_iteration = -1\n",
    "for index, row in enumerate(csv.itertuples()):\n",
    "    if csv.at[index, 'epoch'] == 0:\n",
    "        current_iteration += 1\n",
    "    csv.at[index, 'tuner_iteration'] = current_iteration\n",
    "\n",
    "# 2 Tuner iterations are missing in my CSV. \n",
    "# Might the reason be unknown all we know that 42 and 47 are mapped to 40 and 45\n",
    "best_dataframe = csv.query(\"tuner_iteration in [40, 8, 23, 45, 14]\")"
   ],
   "id": "b55126c0167e1f09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "loss_figure = px.line(csv, x=\"epoch\", y=[\"loss\"], color=\"tuner_iteration\", template=\"plotly_white\",\n",
    "                      markers=True)\n",
    "loss_figure.update_layout(title=\"Loss in tuner search\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")"
   ],
   "id": "d0efcce7f5f1796f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "figure = px.line(csv, x=\"epoch\", y=[\"val_loss\"], color=\"tuner_iteration\", template=\"plotly_white\", markers=True)\n",
    "figure.update_layout(title=\"Validation Loss in tuner search\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")"
   ],
   "id": "bbcd0e7a32193ccc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "loss_figure = px.line(best_dataframe, x=\"epoch\", y=[\"loss\"], color=\"tuner_iteration\", template=\"plotly_white\",\n",
    "                      markers=True)\n",
    "loss_figure.update_layout(title=\"Loss in tuner search\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")"
   ],
   "id": "cab687729c4e3fdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "figure = px.line(best_dataframe, x=\"epoch\", y=[\"val_loss\"], color=\"tuner_iteration\", template=\"plotly_white\",\n",
    "                 markers=True)\n",
    "figure.update_layout(title=\"Validation Loss in tuner search\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")"
   ],
   "id": "dc607a72ce3de198",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_hyperparameters_references = [\n",
    "    dict(iteration=40, hyperparameters_index=0),\n",
    "    dict(iteration=8, hyperparameters_index=1),\n",
    "]\n",
    "\n",
    "[print(f\"iteration:{i['iteration']}, hp: {tuner.get_best_hyperparameters(5)[i['hyperparameters_index']].values}\") for i\n",
    " in best_hyperparameters_references]"
   ],
   "id": "d4b6b301e221e2ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test con modello 8 \n",
    "Funziona ora la procedura. Risistema il file"
   ],
   "id": "75a59c291beb7aa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.zero_one_validation_loss import zero_one_loss_binary\n",
    "\n",
    "# Model 8\n",
    "model_family = TunableConvNetFamily()\n",
    "model_family.load_parameters(tuner.get_best_hyperparameters(2)[1])\n",
    "model_family.parameters_fixed = True\n",
    "\n",
    "project_name = \"random-search-best-8-hp-env\"\n",
    "directory = \"cnn_search\"\n",
    "\n",
    "learning_parameters = HyperParameters()\n",
    "learning_parameters.Choice(name=\"batch_size\", values=[8, 16, 32, 64], default=16)\n",
    "learning_parameters.Float(name=\"lr\", min_value=1e-5, max_value=1e-3, sampling='log', step=2),\n",
    "learning_parameters.Float(name=\"momentum\", min_value=0.5, max_value=1, sampling='reverse_log', step=2)\n",
    "\n",
    "batch_tuner = HistoryDeletingBayesianOptimization(\n",
    "    TunableHyperModel(model_family, SgdLearningParametersTunable(learning_rate=1e-4),\n",
    "                      (3, 224, 224), tune_batch=True, verbose=True),\n",
    "    hyperparameters=learning_parameters,\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=False,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory=directory,\n",
    "    metrics=['accuracy'],\n",
    "    max_trials=10,\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "c6f36e5910092ed9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8989dbaafd375200",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import callbacks.threshold_stop_cb\n",
    "\n",
    "batch_tuner.search(train_dataloader, epochs=1, validation_data=validation_dataloader, callbacks=[\n",
    "    keras.callbacks.CSVLogger(f\"{directory}/{project_name}/search.log\", separator=\",\", append=True),\n",
    "    callbacks.threshold_stop_cb.ThresholdStopCallback(0.6, 4),\n",
    "])"
   ],
   "id": "a5c7656d859ecda1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test con modello 40 (Most promising)",
   "id": "5cbbcf9bbfd742fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Search for best hyperparameters for model 4 and 8: Batch size, and SGD params\n",
    "\n",
    "# Initial steps\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "train, test = dataset_loader((224, 224), is_grayscale=False)\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "# No batch size is fixed\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, shuffle=True)"
   ],
   "id": "ee21dc62b6bc24ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.zero_one_validation_loss import zero_one_loss_binary\n",
    "\n",
    "# Model 8\n",
    "model_family = TunableConvNetFamily()\n",
    "model_family.load_parameters(tuner.get_best_hyperparameters(2)[0])\n",
    "\n",
    "project_name = \"multi-layers-best-model-8-hp-env\"\n",
    "directory = \"cnn_search\"\n",
    "\n",
    "learning_parameters = keras_tuner.HyperParameters()\n",
    "learning_parameters.Choice(name=\"batch_size\", values=[8, 16, 32, 64], default=16)\n",
    "learning_parameters.Float(name=\"lr\", min_value=1e-5, max_value=1e-3, sampling='log', step=2),\n",
    "learning_parameters.Float(name=\"momentum\", min_value=0.5, max_value=1, sampling='reverse_log', step=2)\n",
    "\n",
    "tuner = HistoryDeletingBayesianOptimization(\n",
    "    TunableModelFamilyHypermodel((3, 224, 224), TunableConvNetFamily(), tune_batch=True),\n",
    "    hyperparameters=hyperparameters,\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=False,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory=directory,\n",
    "    metrics=['accuracy', zero_one_loss_binary],\n",
    "    max_trials=10,\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "4bf5a4755a647675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sezione separata: Ricerca piu narrow",
   "id": "d8951d4ce9fa11d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas\n",
    "\n",
    "csv = pandas.read_csv(\"./cnn_search/multi-layers/search.log\")\n",
    "csv['tuner_iteration'] = 0\n",
    "\n",
    "current_iteration = 0\n",
    "for index, row in enumerate(csv.itertuples()):\n",
    "    if csv.at[index, 'epoch'] == 0:\n",
    "        current_iteration += 1\n",
    "    csv.at[index, 'tuner_iteration'] = current_iteration\n",
    "\n",
    "best_dataframe = csv.query(\"tuner_iteration in [8, 4, 12, 2, 10]\")"
   ],
   "id": "6d3262e9f1287267",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "loss_figure = px.line(best_dataframe, x=\"epoch\", y=[\"loss\"], color=\"tuner_iteration\", template=\"plotly_white\",\n",
    "                      markers=True)\n",
    "loss_figure.update_layout(title=\"Loss in tuner search\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")"
   ],
   "id": "a3b78db09b647072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_hyperparameters_references = [\n",
    "    dict(iteration=8, hyperparameters_index=0),\n",
    "    dict(iteration=4, hyperparameters_index=1),\n",
    "]\n",
    "\n",
    "[print(f\"iteration:{i['iteration']}, hp: {tuner.get_best_hyperparameters(5)[i['hyperparameters_index']].values}\") for i\n",
    " in best_hyperparameters_references]"
   ],
   "id": "a0bfb667331e18f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "loss_figure = px.line(best_dataframe, x=\"epoch\", y=[\"loss\"], color=\"tuner_iteration\", template=\"plotly_white\",\n",
    "                      markers=True)\n",
    "loss_figure.update_layout(title=\"Loss in tuner search\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")"
   ],
   "id": "abbd85e88dc5614b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "figure = px.line(best_dataframe, x=\"epoch\", y=[\"val_loss\"], color=\"tuner_iteration\", template=\"plotly_white\",\n",
    "                 markers=True)\n",
    "figure.update_layout(title=\"Validation Loss in tuner search\", xaxis_title=\"Epoch\", yaxis_title=\"Loss\")"
   ],
   "id": "22b295608bbc95f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# 4 Looks promising and also 8 is good. We keep those two",
   "id": "fb19f4fc1d5f5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_hyperparameters_references = [\n",
    "    dict(iteration=8, hyperparameters_index=0),\n",
    "    dict(iteration=4, hyperparameters_index=1),\n",
    "]\n",
    "\n",
    "[print(f\"iteration:{i['iteration']}, hp: {tuner.get_best_hyperparameters(5)[i['hyperparameters_index']].values}\") for i\n",
    " in best_hyperparameters_references]"
   ],
   "id": "a1810540d54ce002",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Search for best hyperparameters for model 4 and 8: Batch size, and SGD params\n",
    "\n",
    "# Initial steps\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "train, test = dataset_loader((224, 224), is_grayscale=False)\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "# No batch size is fixed\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, shuffle=True)"
   ],
   "id": "862d5e282143355b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Model 8 Summary\n",
    "model_family = TunableConvNetFamily()\n",
    "model_family.load_parameters(tuner.get_best_hyperparameters(2)[0])\n",
    "\n",
    "temp_model = model_family.make_model((3, 224, 224))\n",
    "model_family.compile_model(temp_model)\n",
    "\n",
    "temp_model.summary()"
   ],
   "id": "acb9c2369a4be34c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.zero_one_validation_loss import zero_one_loss_binary\n",
    "\n",
    "# Model 8\n",
    "model_family = TunableConvNetFamily()\n",
    "model_family.load_parameters(tuner.get_best_hyperparameters(2)[0])\n",
    "\n",
    "project_name = \"multi-layers-best-model-8-hp-env\"\n",
    "directory = \"cnn_search\"\n",
    "\n",
    "learning_parameters = keras_tuner.HyperParameters()\n",
    "learning_parameters.Choice(name=\"batch_size\", values=[8, 16, 32, 64], default=16)\n",
    "learning_parameters.Float(name=\"lr\", min_value=1e-5, max_value=1e-3, sampling='log', step=2),\n",
    "learning_parameters.Float(name=\"momentum\", min_value=0.5, max_value=1, sampling='reverse_log', step=2)\n",
    "\n",
    "tuner = HistoryDeletingBayesianOptimization(\n",
    "    TunableModelFamilyHypermodel((3, 224, 224), TunableConvNetFamily(), tune_batch=True),\n",
    "    hyperparameters=hyperparameters,\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=False,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory=directory,\n",
    "    metrics=['accuracy', zero_one_loss_binary],\n",
    "    max_trials=10,\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "1a70899683ab63d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import callbacks.threshold_stop_cb\n",
    "\n",
    "tuner.search(train_dataloader, epochs=12, validation_data=validation_dataloader, callbacks=[\n",
    "    keras.callbacks.CSVLogger(f\"{directory}/{project_name}/search.log\", separator=\",\", append=True),\n",
    "    callbacks.threshold_stop_cb.ThresholdStopCallback(0.5, 4),\n",
    "])"
   ],
   "id": "c04950a8d3012e61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.zero_one_validation_loss import zero_one_loss_binary\n",
    "\n",
    "# Model 4\n",
    "model_family = TunableConvNetFamily()\n",
    "model_family.load_parameters(tuner.get_best_hyperparameters(2)[1])\n",
    "\n",
    "learning_parameters = keras_tuner.HyperParameters()\n",
    "learning_parameters.Choice(name=\"batch_size\", values=[8, 16, 32, 64], default=16)\n",
    "learning_parameters.Float(name=\"lr\", min_value=1e-5, max_value=1e-3, sampling='log', step=2),\n",
    "learning_parameters.Float(name=\"momentum\", min_value=0.5, max_value=1, sampling='reverse_log', step=2)\n",
    "\n",
    "project_name = \"multi-layers-best-model-4-hp-env\"\n",
    "directory = \"cnn_search\"\n",
    "\n",
    "tuner = HistoryDeletingBayesianOptimization(\n",
    "    TunableModelFamilyHypermodel((3, 224, 224), TunableConvNetFamily(), tune_batch=True),\n",
    "    hyperparameters=hyperparameters,\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=False,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory=directory,\n",
    "    max_trials=10,\n",
    "    metrics=['accuracy', zero_one_loss_binary],\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "63c4b9f1461c6b86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import callbacks.threshold_stop_cb\n",
    "\n",
    "tuner.search(train_dataloader, epochs=12, validation_data=validation_dataloader, callbacks=[\n",
    "    keras.callbacks.CSVLogger(f\"{directory}/{project_name}/search.log\", separator=\",\", append=True),\n",
    "    callbacks.threshold_stop_cb.ThresholdStopCallback(0.5, 4),\n",
    "])"
   ],
   "id": "c4f13df54f6204b7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
