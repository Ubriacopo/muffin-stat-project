{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conv Net Family: Model 8 of keras tuner",
   "id": "94e2b4b9f628e398"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We reference the best hyperparameter iteration  8 (being second best)",
   "id": "95f2eac536d0d532"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1 - Model Ad Hoc Definition",
   "id": "92a5677c6ca7b731"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:09:17.602219Z",
     "start_time": "2024-05-12T09:09:15.616954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from utils.my_tuner import HistoryDeletingRandomSearch\n",
    "\n",
    "project_name = \"random-search-rich-structure\"\n",
    "directory = \"cnn_search\"\n",
    "\n",
    "# Load previous hypertuner\n",
    "previous_tuner = HistoryDeletingRandomSearch(None, overwrite=False, project_name=project_name, directory=directory)\n",
    "previous_tuner.get_best_hyperparameters(2)[1].values"
   ],
   "id": "4811d5812bdb7f13",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The tuner yielded a model with only one conv layer (64, (5x5)) and a hidden activation layer with 256 units.\n",
    "\n",
    "To avoid loading the parameters from tuner story we simply redefine in order to fix the structure."
   ],
   "id": "e24608808a174dd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:09:17.633341Z",
     "start_time": "2024-05-12T09:09:17.602980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Final\n",
    "from models.structure.layer_structure_data import ConvLayerStructure, PoolLayerStructure, HiddenLayerStructure\n",
    "from models.simple_cnn.conv_net_family import TunableConvNetFamily\n",
    "\n",
    "\n",
    "# Definition on the tuner parameters.\n",
    "class ConvNetFamilyModel8(TunableConvNetFamily):\n",
    "    convolution_layers: list[tuple[ConvLayerStructure, PoolLayerStructure | None]] = [\n",
    "        (ConvLayerStructure((5, 5), 64), PoolLayerStructure((2, 2), 2)),\n",
    "    ]\n",
    "\n",
    "    dense_layers: list[HiddenLayerStructure] = [\n",
    "        HiddenLayerStructure(256, None),\n",
    "    ]\n",
    "\n",
    "    # We won't allow to override the configuration of this structure\n",
    "    parameters_fixed: Final[bool] = True"
   ],
   "id": "6f8ee5d65f4f38db",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 - Learning parameters tuning via Keras Tuner",
   "id": "a91d7b533370dde9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:09:17.635500Z",
     "start_time": "2024-05-12T09:09:17.633980Z"
    }
   },
   "cell_type": "code",
   "source": "model_wrapper = ConvNetFamilyModel8()",
   "id": "3f55475daca10f26",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 - Setting parameters",
   "id": "114756343b363b48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:09:17.638726Z",
     "start_time": "2024-05-12T09:09:17.636338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras_tuner import HyperParameters\n",
    "\n",
    "learning_parameters = HyperParameters()\n",
    "learning_parameters.Choice(name=\"batch_size\", values=[8, 16, 32, 64], default=16)\n",
    "learning_parameters.Float(name=\"lr\", min_value=1e-5, max_value=1e-3, sampling='log', step=2)\n",
    "learning_parameters.Float(name=\"momentum\", min_value=0.5, max_value=1, step=0.05, default=0.5)"
   ],
   "id": "39f1fecec8f1",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 - Loading data",
   "id": "f0fe9e7e8599c197"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:09:17.818489Z",
     "start_time": "2024-05-12T09:09:17.639211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset.dataset_loader import prepare_dataloaders, dataset_loader\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper\n",
    "\n",
    "# Load all the data\n",
    "train, test = dataset_loader((224, 224), is_grayscale=False)\n",
    "\n",
    "# Split it to creat a validation split as we don't want to use the test data\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "train_dataloader, validation_dataloader = prepare_dataloaders(\n",
    "    dataset_split_controller.get_data_for_fold(0), None)"
   ],
   "id": "555f55e7319a71ef",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 - Setting up the tuner\n",
    "Before setting we decide our metrics:"
   ],
   "id": "e197a17df1e1136b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:09:17.820589Z",
     "start_time": "2024-05-12T09:09:17.819115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"random-search-best-8-hp\"\n",
    "directory = \"cnn_search\""
   ],
   "id": "66cff9ddbfb59fb5",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:09:17.897388Z",
     "start_time": "2024-05-12T09:09:17.821087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.zero_one_validation_loss import ZeroOneLoss, iter_0_1_loss\n",
    "\n",
    "metrics = ['accuracy', iter_0_1_loss, ZeroOneLoss()]"
   ],
   "id": "f080c4ea268d2057",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:09:17.902567Z",
     "start_time": "2024-05-12T09:09:17.898035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.my_tuner import HistoryDeletingBayesianOptimization\n",
    "from models.structure.learning_parameters.sgd_learning_parameters import SgdLearningParametersTunable\n",
    "from models.structure.tunable_hypermodel import TunableHyperModel\n",
    "\n",
    "# Learning parameters. We use SGD as reported for various reasons\n",
    "tunable_learning_parameters = SgdLearningParametersTunable(learning_rate=1e-4)\n",
    "hypermodel = TunableHyperModel(model_wrapper, tunable_learning_parameters, (3, 224, 224), tune_batch=True)\n",
    "batch_tuner = HistoryDeletingBayesianOptimization(\n",
    "    hypermodel,\n",
    "    hyperparameters=learning_parameters,\n",
    "\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=False,\n",
    "    \n",
    "    overwrite=False,\n",
    "\n",
    "    metrics=['accuracy', iter_0_1_loss, ZeroOneLoss()],\n",
    "    max_trials=40,\n",
    "\n",
    "    directory=directory,\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "dd293509f39eece6",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import callbacks.threshold_stop_cb\n",
    "\n",
    "batch_tuner.search(train_dataloader, epochs=15, validation_data=validation_dataloader, callbacks=[\n",
    "    keras.callbacks.CSVLogger(f\"{directory}/{project_name}/search.log\", separator=\",\", append=True),\n",
    "    callbacks.threshold_stop_cb.ThresholdStopCallback(0.6, 4),\n",
    "])"
   ],
   "id": "57d8492a71132a",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3 - Check the results",
   "id": "beec09482cf410e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T18:31:23.180622Z",
     "start_time": "2024-05-12T18:31:23.178057Z"
    }
   },
   "cell_type": "code",
   "source": "batch_tuner.results_summary()",
   "id": "d0da0d2d55b6b5cf",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T18:31:48.660472Z",
     "start_time": "2024-05-12T18:31:48.632410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas\n",
    "from utils.data_processing import add_tuner_iteration_to_data\n",
    "\n",
    "csv = pandas.read_csv(f\"./cnn_search/{project_name}/search.log\")\n",
    "add_tuner_iteration_to_data(csv)\n",
    "\n",
    "# 2 Tuner iterations are missing in my CSV. \n",
    "# Might the reason be unknown all we know that 42 and 47 are mapped to 40 and 45\n",
    "best_dataframe = csv.query(\"tuner_iteration in [16, 36, 21, 31, 22]\")"
   ],
   "id": "7b6eeaefb335d7fb",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T18:31:49.407713Z",
     "start_time": "2024-05-12T18:31:49.266996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.data_processing import make_loss_graphs, make_loss_accuracy_graphs\n",
    "\n",
    "loss_graph = make_loss_graphs(best_dataframe)\n",
    "loss_graph.update_layout(title=\"Loss vs Val_loss in tuner search per epoch (Val dashed)\")\n",
    "\n",
    "acc_graph = make_loss_accuracy_graphs(best_dataframe)\n",
    "acc_graph.update_layout(title=\"Accuracy vs Val_Accuracy in tuner search per epoch (Val dashed)\")\n",
    "\n",
    "loss_graph.show()\n",
    "acc_graph.show()"
   ],
   "id": "2cb8a3aa0988dc20",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A questo punto uso k-fold cv?",
   "id": "59671f3fc3dd7446"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 - K-fold on the resulting model",
   "id": "a2b3fa651b1b493"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5451dc26c49f7ae2",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# For some reason skipped trial 1",
   "id": "f231ff06c6bb55c8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch_tuner.get_best_hyperparameters(5)[0].values",
   "id": "eff355abbbc86c6f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We choose to take the best parameters (Top 3 are all the same)\n",
    "best_hyperparameters = batch_tuner.get_best_hyperparameters(5)[0]\n",
    "\n",
    "train, test = dataset_loader((224, 224), is_grayscale=False)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train, batch_size=batch_tuner.get_best_hyperparameters(5)[0]['batch_size'],\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test, batch_size=batch_tuner.get_best_hyperparameters(5)[0]['batch_size'],\n",
    "                             shuffle=True)\n",
    "\n",
    "sgd_learning_parameters = SgdLearningParametersTunable(1e-4, metrics=['accuracy', iter_0_1_loss, ZeroOneLoss()])\n",
    "\n",
    "sgd_learning_parameters.load_parameters(best_hyperparameters)\n",
    "model = model_family.make_model((3, 224, 224))\n",
    "\n",
    "sgd_learning_parameters.compile_model(model)\n",
    "model.summary()"
   ],
   "id": "b4abcdbc0fd3bed6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.optimizer.get_config()",
   "id": "1295f6f4649963e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.fit(train_dataloader, epochs=10, callbacks=[\n",
    "    keras.callbacks.CSVLogger(f\"{directory}/{project_name}/best_params_search.log\", separator=\",\", append=True),\n",
    "])"
   ],
   "id": "feb9e9215771f2cc",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.evaluate(test_dataloader)",
   "id": "c59bea82ea899534",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With only 10 epochs we have a 0.35 loss on test. Which is in line with the results",
   "id": "e8b3d74ae0a988af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = model.fit(train_dataloader, epochs=10, callbacks=[\n",
    "    keras.callbacks.CSVLogger(f\"{directory}/{project_name}/best_params_search.log\", separator=\",\", append=True),\n",
    "])"
   ],
   "id": "13fa5baeb371ace2",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.evaluate(test_dataloader)",
   "id": "d4b1de81c09cb4a0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# We are overfitting. The accuracy decreasded on test ( stayed more or less the same) and the model fit better",
   "id": "b2786d071e56262f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6c71b304bbc7d613",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "previous_tuner.get_best_hyperparameters(2)[1].values",
   "id": "b760c4056165c655",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.structure.augmentation_wrapper import InvertedAugmentationWrapper\n",
    "\n",
    "best_hyperparameters = batch_tuner.get_best_hyperparameters(5)[0]\n",
    "\n",
    "\n",
    "# Use Augmentation to increase the performance\n",
    "class AugmentedConvNetFamily(TunableConvNetFamily, InvertedAugmentationWrapper):\n",
    "    pass\n",
    "\n",
    "\n",
    "augmented_family = AugmentedConvNetFamily()\n",
    "augmented_family.load_parameters(previous_tuner.get_best_hyperparameters(2)[1])\n",
    "\n",
    "model = augmented_family.make_model((3, 224, 224))\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train, batch_size=batch_tuner.get_best_hyperparameters(5)[0]['batch_size'],\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test, batch_size=batch_tuner.get_best_hyperparameters(5)[0]['batch_size'],\n",
    "                             shuffle=True)\n",
    "\n",
    "sgd_learning_parameters = SgdLearningParametersTunable(1e-4, metrics=['accuracy', iter_0_1_loss, ZeroOneLoss()])\n",
    "\n",
    "sgd_learning_parameters.load_parameters(best_hyperparameters)\n",
    "sgd_learning_parameters.compile_model(model)\n",
    "\n",
    "model.summary(expand_nested=True)"
   ],
   "id": "2a11f333fe6b8720",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://www.deeplearningbook.org/contents/optimization.html\n",
    "model.fit(train_dataloader, epochs=12, callbacks=[\n",
    "    keras.callbacks.CSVLogger(f\"{directory}/{project_name}/best_params_search_aug.log\", separator=\",\", append=True),\n",
    "])"
   ],
   "id": "4adbe1c51fa05c92",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.evaluate(test_dataloader)",
   "id": "4e4842aa2691ed39",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Use nested K Fold to tune epoches and then train on best",
   "id": "38fc42c32279af6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Use K fold CV to tune epoches and avoid early stopping",
   "id": "136a056d1e0d8780",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Use early stopping with a validation split",
   "id": "c5dfb38c09646069"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2e271927cd7b1b35",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
