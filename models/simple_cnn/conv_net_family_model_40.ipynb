{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conv Net Family: Model 40 of keras tuner",
   "id": "42f5688fded36be4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We reference the best hyperparameter iteration  8 (being second best)",
   "id": "c5c5c698f51b6295"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1 - Model Ad Hoc Definition",
   "id": "f5caf06e81de400c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:14:33.834894Z",
     "start_time": "2024-05-12T19:14:31.837773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from utils.my_tuner import HistoryDeletingRandomSearch\n",
    "\n",
    "project_name = \"random-search-rich-structure\"\n",
    "directory = \"cnn_search\"\n",
    "\n",
    "# Load previous hypertuner\n",
    "previous_tuner = HistoryDeletingRandomSearch(None, overwrite=False, project_name=project_name, directory=directory)\n",
    "previous_tuner.get_best_hyperparameters(2)[0].values"
   ],
   "id": "616d1eab98934e45",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:14:33.864652Z",
     "start_time": "2024-05-12T19:14:33.835607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Final\n",
    "from models.structure.layer_structure_data import ConvLayerStructure, PoolLayerStructure, HiddenLayerStructure\n",
    "from models.simple_cnn.conv_net_family import TunableConvNetFamily\n",
    "\n",
    "\n",
    "# Definition on the tuner parameters.\n",
    "class ConvNetFamilyModel40(TunableConvNetFamily):\n",
    "    convolution_layers: list[tuple[ConvLayerStructure, PoolLayerStructure | None]] = [\n",
    "        (ConvLayerStructure((3, 3), 64), PoolLayerStructure((2, 2), 2)),\n",
    "        (ConvLayerStructure((5, 5), 64), PoolLayerStructure((2, 2), 2))\n",
    "    ]\n",
    "\n",
    "    dense_layers: list[HiddenLayerStructure] = [\n",
    "        HiddenLayerStructure(128, None),\n",
    "        HiddenLayerStructure(64, None)\n",
    "    ]\n",
    "\n",
    "    # We won't allow to override the configuration of this structure\n",
    "    parameters_fixed: Final[bool] = True"
   ],
   "id": "9ae89423d143faf6",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 - Learning parameters tuning via Keras Tuner",
   "id": "6a051252cd0b645"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:14:33.866890Z",
     "start_time": "2024-05-12T19:14:33.865299Z"
    }
   },
   "cell_type": "code",
   "source": "model_wrapper = ConvNetFamilyModel40()",
   "id": "aeca586584e4d303",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 - Setting parameters",
   "id": "763008df3983e24c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:14:33.870519Z",
     "start_time": "2024-05-12T19:14:33.867822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras_tuner import HyperParameters\n",
    "\n",
    "learning_parameters = HyperParameters()\n",
    "learning_parameters.Choice(name=\"batch_size\", values=[8, 16, 32, 64], default=16)\n",
    "learning_parameters.Float(name=\"lr\", min_value=1e-5, max_value=1e-3, sampling='log', step=2)\n",
    "learning_parameters.Float(name=\"momentum\", min_value=0.5, max_value=1, step=0.05, default=0.5)"
   ],
   "id": "37df337415370977",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 - Loading data",
   "id": "8b2ff948dda86388"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:14:34.059958Z",
     "start_time": "2024-05-12T19:14:33.871050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset.dataset_loader import prepare_dataloaders, dataset_loader\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper\n",
    "\n",
    "# Load all the data\n",
    "train, test = dataset_loader((224, 224), is_grayscale=False)\n",
    "\n",
    "# Split it to creat a validation split as we don't want to use the test data\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "train_dataloader, validation_dataloader = prepare_dataloaders(\n",
    "    dataset_split_controller.get_data_for_fold(0), None)"
   ],
   "id": "a2146316304777e7",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 - Setting up the tuner\n",
    "Before setting we decide our metrics:"
   ],
   "id": "e88c04fcc23a9626"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:14:34.062165Z",
     "start_time": "2024-05-12T19:14:34.060600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"random-search-best-40-hp\"\n",
    "directory = \"cnn_search\""
   ],
   "id": "70af54eeb83b9654",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:14:34.150678Z",
     "start_time": "2024-05-12T19:14:34.062699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.zero_one_validation_loss import ZeroOneLoss, iter_0_1_loss\n",
    "\n",
    "metrics = ['accuracy', iter_0_1_loss, ZeroOneLoss()]"
   ],
   "id": "c25f422a8aa5a226",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:14:34.281030Z",
     "start_time": "2024-05-12T19:14:34.151299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.my_tuner import HistoryDeletingBayesianOptimization\n",
    "from models.structure.learning_parameters.sgd_learning_parameters import SgdLearningParametersTunable\n",
    "from models.structure.tunable_hypermodel import TunableHyperModel\n",
    "\n",
    "# Learning parameters. We use SGD as reported for various reasons\n",
    "tunable_learning_parameters = SgdLearningParametersTunable(learning_rate=1e-4)\n",
    "hypermodel = TunableHyperModel(model_wrapper, tunable_learning_parameters, (3, 224, 224), tune_batch=True)\n",
    "batch_tuner = HistoryDeletingBayesianOptimization(\n",
    "    hypermodel,\n",
    "    hyperparameters=learning_parameters,\n",
    "\n",
    "    objective='val_loss',\n",
    "    tune_new_entries=False,\n",
    "\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "\n",
    "    metrics=['accuracy', iter_0_1_loss, ZeroOneLoss()],\n",
    "    max_trials=20,\n",
    "\n",
    "    directory=directory,\n",
    "    project_name=project_name\n",
    ")"
   ],
   "id": "28a08dbe0dd6381",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import callbacks.threshold_stop_cb\n",
    "\n",
    "batch_tuner.search(train_dataloader, epochs=15, validation_data=validation_dataloader, callbacks=[\n",
    "    keras.callbacks.CSVLogger(f\"{directory}/{project_name}/search.log\", separator=\",\", append=True),\n",
    "    callbacks.threshold_stop_cb.ThresholdStopCallback(0.6, 4),\n",
    "])"
   ],
   "id": "678193fe975eb164",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3 - Check the results",
   "id": "5d271dab00a006f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper\n",
    "from dataset.dataset_loader import dataset_loader\n",
    "import keras_tuner\n",
    "\n",
    "# Search for best hyperparameters for model 4 and 8: Batch size, and SGD params\n",
    "\n",
    "# Initial steps\n",
    "hyperparameters = keras_tuner.HyperParameters()\n",
    "train, test = dataset_loader((224, 224), is_grayscale=False)\n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "# No batch size is fixed\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "train_dataloader = DataLoader(dataset=local_train, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, shuffle=True, batch_size=32)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 - K-fold on the resulting model",
   "id": "e8b6f9ed8b7b88ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1a5fb332ea21e430",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
