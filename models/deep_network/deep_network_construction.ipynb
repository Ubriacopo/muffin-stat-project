{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T22:13:59.982432Z",
     "start_time": "2024-05-15T22:13:59.980119Z"
    }
   },
   "source": "default_values = {\"batch_size\": 32, \"epochs\": 20, \"learning_rate\": 1e-3}",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We want start by creating a custom simple DNN.\n",
    "\n",
    "# 1 - Load data\n",
    "Total splitting of data will be [64%, 16%, 20%] (If we consider test and train to be the full set) <br />\n",
    "Best practices suggest to go for a [70%, 15%, 15%] splitting but we will just keep it this way."
   ],
   "id": "6a7914d43ec39f64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:14:01.796706Z",
     "start_time": "2024-05-15T22:13:59.999706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import models.structure.base_model_wrapper\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset_loader import dataset_loader\n",
    "\n",
    "train, test = dataset_loader((160, 160), is_grayscale=False)\n",
    "\n",
    "# We take 20% of train as validation. \n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=default_values[\"batch_size\"], shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=default_values[\"batch_size\"], shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test, batch_size=default_values[\"batch_size\"], shuffle=True)"
   ],
   "id": "93d280da62d3480f",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2 - First model\n",
    "Our first model is a simple CNN. <br><br />\n",
    "\n",
    "\n",
    "## 2.1 - Model definition "
   ],
   "id": "f6c4f7d66f88828d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:14:01.799247Z",
     "start_time": "2024-05-15T22:14:01.797532Z"
    }
   },
   "cell_type": "code",
   "source": "project_definition: dict[str, any] = {\"name\": \"hand_tailored_v1\"}",
   "id": "3ae85a143a39d3d5",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:14:01.802044Z",
     "start_time": "2024-05-15T22:14:01.799771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Input, Flatten, Dense, Layer\n",
    "from models.structure.base_model_wrapper import BaseModelWrapper\n",
    "\n",
    "\n",
    "class HandTailoredDeepNet(BaseModelWrapper):\n",
    "    def make_layers(self, input_shape: (int, int, int)) -> tuple[Layer, Layer]:\n",
    "        input_layer = Input(shape=input_shape, name=self.__class__.__name__)\n",
    "        x = Flatten(data_format=self.data_format.value)(input_layer)\n",
    "        \n",
    "        # The number I chose are arbitrary\n",
    "        x = Dense(units=2048, activation='relu')(x)\n",
    "        x = Dense(units=720, activation=\"relu\")(x)\n",
    "        output_layer = Dense(units=1, activation=\"sigmoid\")(x)\n",
    "        \n",
    "        return input_layer, output_layer"
   ],
   "id": "cf2b6261d102fb74",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 - Model instance and learning",
   "id": "fe5601e518d4b054"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:14:02.184434Z",
     "start_time": "2024-05-15T22:14:01.802713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.learning_parameters.sgd_learning_parameters import SgdLearningParameters\n",
    "\n",
    "model = HandTailoredDeepNet().make_model((3, 160, 160))\n",
    "# Default Keras learning-rate Value (0.01) doesnt work. \n",
    "# We always have a huge loss therefore we decrease it.\n",
    "SgdLearningParameters(learning_rate=1e-3).compile_model(model)\n",
    "\n",
    "model.summary()"
   ],
   "id": "7c0e45bc3d96f09b",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:28:55.473205Z",
     "start_time": "2024-05-15T22:14:02.185045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "# We fix the number of epochs for now. Later we will add early stopping.\n",
    "model.fit(x=train_dataloader, validation_data=validation_dataloader, epochs=default_values[\"epochs\"], callbacks=[\n",
    "    # To persist the history\n",
    "    keras.callbacks.CSVLogger(f\"{project_definition['name']}_train.csv\", separator=\",\", append=True)\n",
    "])\n",
    "\n",
    "persist_model: bool = True\n",
    "if persist_model:\n",
    "    model.save(f'{project_definition[\"name\"]}.keras')"
   ],
   "id": "312a95545f20a9b4",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:29:06.749939Z",
     "start_time": "2024-05-15T22:28:55.473979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = model.evaluate(test_dataloader)\n",
    "print(f\"Test accuracy is {res[1] * 100:.2f}% while loss is {res[0]}\")"
   ],
   "id": "9321075a97a1d9ce",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 - Results summary",
   "id": "5df85a247d3c5c27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:29:37.603646Z",
     "start_time": "2024-05-15T22:29:37.501105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.data_processing import make_loss_graphs, make_loss_accuracy_graphs, add_tuner_iteration_to_data\n",
    "import pandas\n",
    "\n",
    "csv = pandas.read_csv(f\"{project_definition['name']}_train.csv\")\n",
    "add_tuner_iteration_to_data(csv)\n",
    "\n",
    "loss_graph = make_loss_graphs(csv)\n",
    "acc_graph = make_loss_accuracy_graphs(csv)\n",
    "\n",
    "loss_graph.update_layout(title=\"Loss vs Val_loss in tuner search per epoch (Val dashed)\").show()\n",
    "acc_graph.update_layout(title=\"Accuracy vs Val_Accuracy in tuner search per epoch (Val dashed)\").show()"
   ],
   "id": "70dbfcf8c1796126",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As learning hp are not fine tuned we can expect the learning process to improve by studying them (learning is very slow right now). \n",
    "Yet the network size is insanely huge\n",
    "compared to a better (even if hardly overfitting) CNN so unless the memory imprint can be reduced the CNN is our way to go.\n",
    "\n",
    "(It seems like we are underfitting)"
   ],
   "id": "e43593312fbf890"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Considering the previous results it would be interesting to see if it is possible to make a smaller model able to generalize the function.\n",
    "# 3 - Smaller model"
   ],
   "id": "fd06e643caac1b65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 - Model definition\n",
   "id": "d70c30aedc0542fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:30:16.612999Z",
     "start_time": "2024-05-15T22:30:16.610947Z"
    }
   },
   "cell_type": "code",
   "source": "project_definition: dict[str, any] = {\"name\": \"hand_tailored_small\"}",
   "id": "cc228b699d13b6e8",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:31:10.470971Z",
     "start_time": "2024-05-15T22:31:10.468276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Input, Flatten, Dense, Layer\n",
    "from models.structure.base_model_wrapper import BaseModelWrapper\n",
    "\n",
    "# This model is still 100MB bigger than the biggest CNN we have\n",
    "class SmallHandTailoredDeepNet(BaseModelWrapper):\n",
    "    def make_layers(self, input_shape: (int, int, int)) -> tuple[Layer, Layer]:\n",
    "        input_layer = Input(shape=input_shape, name=self.__class__.__name__)\n",
    "        x = Flatten(data_format=self.data_format.value)(input_layer)\n",
    "\n",
    "        # The number I chose are arbitrary\n",
    "        x = Dense(units=960, activation='relu')(x)\n",
    "        x = Dense(units=128, activation=\"relu\")(x)\n",
    "        \n",
    "        output_layer = Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        return input_layer, output_layer"
   ],
   "id": "9e40685345ea3748",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 - Model instance and learning",
   "id": "305525f40a5c3b4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:37:51.085057Z",
     "start_time": "2024-05-15T22:37:51.067237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.learning_parameters.sgd_learning_parameters import SgdLearningParameters\n",
    "\n",
    "model = SmallHandTailoredDeepNet().make_model((3, 160, 160))\n",
    "# Default Keras learning-rate Value (0.01) doesnt work. \n",
    "# We always have a huge loss therefore we decrease it.\n",
    "SgdLearningParameters(learning_rate=0.005).compile_model(model)\n",
    "\n",
    "model.summary()"
   ],
   "id": "b716757bf9466b39",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:51:57.477243Z",
     "start_time": "2024-05-15T22:37:51.724889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "# We fix the number of epochs for now. Later we will add early stopping.\n",
    "model.fit(x=train_dataloader, validation_data=validation_dataloader, epochs=default_values[\"epochs\"], callbacks=[\n",
    "    # To persist the history\n",
    "    keras.callbacks.CSVLogger(f\"{project_definition['name']}_train.csv\", separator=\",\", append=True)\n",
    "])\n",
    "\n",
    "persist_model: bool = True\n",
    "if persist_model:\n",
    "    model.save(f'{project_definition[\"name\"]}.keras')"
   ],
   "id": "f1e307a4588d2fd7",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T22:52:08.869666Z",
     "start_time": "2024-05-15T22:51:57.478106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = model.evaluate(test_dataloader)\n",
    "print(f\"Test accuracy is {res[1] * 100:.2f}% while loss is {res[0]}\")"
   ],
   "id": "c61f5f391a355ee1",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.3 - Results summary",
   "id": "4834cf3cd4c6614"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.data_processing import make_loss_graphs, make_loss_accuracy_graphs, add_tuner_iteration_to_data\n",
    "import pandas\n",
    "\n",
    "csv = pandas.read_csv(f\"{project_definition['name']}_train.csv\")\n",
    "add_tuner_iteration_to_data(csv)\n",
    "\n",
    "loss_graph = make_loss_graphs(csv)\n",
    "acc_graph = make_loss_accuracy_graphs(csv)\n",
    "\n",
    "loss_graph.update_layout(title=\"Loss vs Val_loss in tuner search per epoch (Val dashed)\").show()\n",
    "acc_graph.update_layout(title=\"Accuracy vs Val_Accuracy in tuner search per epoch (Val dashed)\").show()"
   ],
   "id": "e1ebd55d7f628922",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model is underfitting. We require more data and/or a richer network.",
   "id": "7ea5f3a573e53adb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "943e0e6a08b26f09",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
