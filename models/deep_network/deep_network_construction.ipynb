{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T21:12:40.291527Z",
     "start_time": "2024-05-27T21:12:40.289637Z"
    }
   },
   "source": "default_values = {\"batch_size\": 32, \"epochs\": 15, \"learning_rate\": 1e-3}",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:32.907385Z",
     "start_time": "2024-05-22T16:17:32.905429Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "We want start by creating a custom simple DNN.\n",
    "\n",
    "# 1 - Load data\n",
    "Total splitting of data will be [64%, 16%, 20%] (If we consider test and train to be the full set) <br />\n",
    "Best practices suggest to go for a [70%, 15%, 15%] splitting but we will just keep it this way."
   ],
   "id": "6a7914d43ec39f64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:12:41.257761Z",
     "start_time": "2024-05-27T21:12:41.243874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import models.structure.base_model_wrapper\n",
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset_loader import dataset_loader, dataset_information\n",
    "\n",
    "train, test = dataset_loader((224, 224))\n",
    "# todo rewrite some of it to be consistent\n",
    "# We take 20% of train as validation. \n",
    "dataset_split_controller = KFoldDatasetWrapper(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=local_train, batch_size=default_values[\"batch_size\"], shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation, batch_size=default_values[\"batch_size\"], shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test, batch_size=default_values[\"batch_size\"], shuffle=True)"
   ],
   "id": "93d280da62d3480f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:13:45.886706Z",
     "start_time": "2024-05-27T21:13:10.899634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean, variance = dataset_information(local_train, (224, 224))\n",
    "measures = {\"mean\": mean, \"variance\": variance}"
   ],
   "id": "64e2f849f20b854",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:49:08.370188Z",
     "start_time": "2024-05-22T20:49:08.365611Z"
    }
   },
   "cell_type": "code",
   "source": "measures",
   "id": "d5187bf5c39444ce",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T16:15:27.200069Z",
     "start_time": "2024-05-22T16:14:54.358204Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "# 2 - First model\n",
    "Our first model is a simple CNN. <br><br />\n",
    "\n",
    "\n",
    "## 2.1 - Model definition "
   ],
   "id": "f6c4f7d66f88828d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:49:30.519148Z",
     "start_time": "2024-05-22T20:49:30.517202Z"
    }
   },
   "cell_type": "code",
   "source": "project_definition: dict[str, any] = {\"name\": \"hand_tailored_v1\"}",
   "id": "3ae85a143a39d3d5",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:49:31.766434Z",
     "start_time": "2024-05-22T20:49:31.760918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.augmentation_wrapper import NormalizedModelWrapper\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, Flatten, Dense, Layer\n",
    "\n",
    "\n",
    "class HandTailoredDeepNet(NormalizedModelWrapper):\n",
    "    def make_layers(self, input_shape: (int, int, int)) -> tuple[Layer, Layer]:\n",
    "        input_layer = Input(shape=input_shape, name=self.__class__.__name__)\n",
    "        x = Flatten(data_format=self.data_format.value)(input_layer)\n",
    "\n",
    "        # The number I chose are arbitrary\n",
    "        x = Dense(units=1024, activation='relu')(x)\n",
    "        x = Dense(units=256, activation=\"relu\")(x)\n",
    "        output_layer = Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        return input_layer, output_layer"
   ],
   "id": "cf2b6261d102fb74",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 - Model instance and learning",
   "id": "fe5601e518d4b054"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:49:41.379559Z",
     "start_time": "2024-05-22T20:49:41.279769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.learning_parameters.sgd_learning_parameters import SgdLearningParameters\n",
    "\n",
    "model_generator = HandTailoredDeepNet()\n",
    "model_generator.load_dataset_mean_and_variance(measures[\"mean\"], measures[\"variance\"])\n",
    "\n",
    "model = model_generator.make_model((3, 224, 224))\n",
    "# Default Keras learning-rate Value (0.01) doesnt work. \n",
    "# We always have a huge loss therefore we decrease it.\n",
    "SgdLearningParameters(learning_rate=1e-3).compile_model(model)\n",
    "\n",
    "model.summary()"
   ],
   "id": "7c0e45bc3d96f09b",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:00:59.428269Z",
     "start_time": "2024-05-22T20:49:46.059848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "# We fix the number of epochs for now. Later we will add early stopping.\n",
    "model.fit(x=train_dataloader, validation_data=validation_dataloader, epochs=default_values[\"epochs\"], callbacks=[\n",
    "    # To persist the history\n",
    "    keras.callbacks.CSVLogger(f\"{project_definition['name']}_train.csv\", separator=\",\", append=True)\n",
    "])\n",
    "\n",
    "persist_model: bool = True\n",
    "if persist_model:\n",
    "    model.save(f'{project_definition[\"name\"]}.keras')"
   ],
   "id": "312a95545f20a9b4",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:01:11.138245Z",
     "start_time": "2024-05-22T21:00:59.429185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = model.evaluate(test_dataloader)\n",
    "print(f\"Test accuracy is {res[1] * 100:.2f}% while loss is {res[0]}\")"
   ],
   "id": "9321075a97a1d9ce",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 - Results summary",
   "id": "5df85a247d3c5c27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:01:11.537305Z",
     "start_time": "2024-05-22T21:01:11.138884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.data_processing import make_loss_graphs, make_loss_accuracy_graphs, add_tuner_iteration_to_data\n",
    "import pandas\n",
    "\n",
    "csv = pandas.read_csv(f\"{project_definition['name']}_train.csv\")\n",
    "add_tuner_iteration_to_data(csv)\n",
    "\n",
    "loss_graph = make_loss_graphs(csv)\n",
    "acc_graph = make_loss_accuracy_graphs(csv)\n",
    "\n",
    "loss_graph.update_layout(title=\"Loss vs Val_loss in tuner search per epoch (Val dashed)\").show()\n",
    "acc_graph.update_layout(title=\"Accuracy vs Val_Accuracy in tuner search per epoch (Val dashed)\").show()"
   ],
   "id": "70dbfcf8c1796126",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are very clearly overfitting. We might reduce the model size to better generalize the data as it is insanely huge right now.",
   "id": "e43593312fbf890"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Considering the previous results it would be interesting to see if it is possible to make a smaller model able to generalize the function.\n",
    "# 3 - Smaller model"
   ],
   "id": "fd06e643caac1b65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 - Model definition\n",
   "id": "d70c30aedc0542fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "project_definition: dict[str, any] = {\"name\": \"hand_tailored_small\"}",
   "id": "cc228b699d13b6e8",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Input, Flatten, Dense, Layer\n",
    "\n",
    "\n",
    "class SmallHandTailoredDeepNet(NormalizedModelWrapper):\n",
    "    def make_layers(self, input_shape: (int, int, int)) -> tuple[Layer, Layer]:\n",
    "        input_layer = Input(shape=input_shape, name=self.__class__.__name__)\n",
    "        x = Flatten(data_format=self.data_format.value)(input_layer)\n",
    "\n",
    "        # The number I chose are arbitrary\n",
    "        x = Dense(units=512, activation='relu')(x)\n",
    "        x = Dense(units=64, activation=\"relu\")(x)\n",
    "\n",
    "        output_layer = Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        return input_layer, output_layer"
   ],
   "id": "9e40685345ea3748",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 - Model instance and learning",
   "id": "305525f40a5c3b4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:01:58.868617Z",
     "start_time": "2024-05-22T21:01:58.843830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.learning_parameters.sgd_learning_parameters import SgdLearningParameters\n",
    "\n",
    "model_generator = SmallHandTailoredDeepNet()\n",
    "model_generator.load_dataset_mean_and_variance(mean, variance)\n",
    "\n",
    "model = model_generator.make_model((3, 224, 224))\n",
    "# Default Keras learning-rate Value (0.01) doesnt work. \n",
    "# We always have a huge loss therefore we decrease it.\n",
    "SgdLearningParameters(learning_rate=1e-3).compile_model(model)\n",
    "\n",
    "model.summary()"
   ],
   "id": "b716757bf9466b39",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:12:42.716630Z",
     "start_time": "2024-05-22T21:02:01.739623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "# We fix the number of epochs for now. Later we will add early stopping.\n",
    "model.fit(x=train_dataloader, validation_data=validation_dataloader, epochs=default_values[\"epochs\"], callbacks=[\n",
    "    # To persist the history\n",
    "    keras.callbacks.CSVLogger(f\"{project_definition['name']}_train.csv\", separator=\",\", append=True)\n",
    "])\n",
    "\n",
    "persist_model: bool = True\n",
    "if persist_model:\n",
    "    model.save(f'{project_definition[\"name\"]}.keras')"
   ],
   "id": "f1e307a4588d2fd7",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:15:27.459255Z",
     "start_time": "2024-05-22T21:15:15.792076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = model.evaluate(test_dataloader)\n",
    "print(f\"Test accuracy is {res[1] * 100:.2f}% while loss is {res[0]}\")"
   ],
   "id": "c61f5f391a355ee1",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.3 - Results summary",
   "id": "4834cf3cd4c6614"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:15:33.246944Z",
     "start_time": "2024-05-22T21:15:33.140700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.data_processing import make_loss_graphs, make_loss_accuracy_graphs, add_tuner_iteration_to_data\n",
    "import pandas\n",
    "\n",
    "csv = pandas.read_csv(f\"{project_definition['name']}_train.csv\")\n",
    "add_tuner_iteration_to_data(csv)\n",
    "\n",
    "loss_graph = make_loss_graphs(csv)\n",
    "acc_graph = make_loss_accuracy_graphs(csv)\n",
    "\n",
    "loss_graph.update_layout(title=\"Loss vs Val_loss in tuner search per epoch (Val dashed)\").show()\n",
    "acc_graph.update_layout(title=\"Accuracy vs Val_Accuracy in tuner search per epoch (Val dashed)\").show()"
   ],
   "id": "e1ebd55d7f628922",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model is still hardly overfitting",
   "id": "7ea5f3a573e53adb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4 - Even smaller model\n",
    "\n",
    "## 4.1 - Model definition"
   ],
   "id": "e7c2820e20dc0696"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:12:26.460121Z",
     "start_time": "2024-05-27T21:12:26.458515Z"
    }
   },
   "cell_type": "code",
   "source": "project_definition: dict[str, any] = {\"name\": \"hand_tailored_xs\"}",
   "id": "2f18b9aeca10618d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:13:00.601162Z",
     "start_time": "2024-05-27T21:13:00.598388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.augmentation_wrapper import NormalizedModelWrapper\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, Flatten, Dense, Layer\n",
    "\n",
    "\n",
    "class VerySmallHandTailoredDeepNet(NormalizedModelWrapper):\n",
    "    def make_layers(self, input_shape: (int, int, int)) -> tuple[Layer, Layer]:\n",
    "        input_layer = Input(shape=input_shape, name=self.__class__.__name__)\n",
    "        x = Flatten(data_format=self.data_format.value)(input_layer)\n",
    "\n",
    "        # The number I chose are arbitrary\n",
    "        x = Dense(units=128, activation='relu')(x)\n",
    "        output_layer = Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        return input_layer, output_layer"
   ],
   "id": "943e0e6a08b26f09",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2 - Model instance and learning",
   "id": "5d1c76c49cce85c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:13:45.984779Z",
     "start_time": "2024-05-27T21:13:45.887551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.structure.learning_parameters.sgd_learning_parameters import SgdLearningParameters\n",
    "\n",
    "model_generator = VerySmallHandTailoredDeepNet()\n",
    "model_generator.load_dataset_mean_and_variance(mean, variance)\n",
    "\n",
    "model = model_generator.make_model((3, 224, 224))\n",
    "# Default Keras learning-rate Value (0.01) doesnt work. \n",
    "# We always have a huge loss therefore we decrease it.\n",
    "SgdLearningParameters(learning_rate=1e-4).compile_model(model)\n",
    "\n",
    "model.summary()"
   ],
   "id": "83109bda547e59d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_5\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ VerySmallHandTailoredDeepNet    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m224\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (\u001B[38;5;33mFunctional\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m224\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_3 (\u001B[38;5;33mFunctional\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │    \u001B[38;5;34m19,267,841\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ VerySmallHandTailoredDeepNet    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │    <span style=\"color: #00af00; text-decoration-color: #00af00\">19,267,841</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m19,267,841\u001B[0m (73.50 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,267,841</span> (73.50 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m19,267,841\u001B[0m (73.50 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,267,841</span> (73.50 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:19:27.752848Z",
     "start_time": "2024-05-27T21:13:45.985423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "# We fix the number of epochs for now. Later we will add early stopping.\n",
    "model.fit(x=train_dataloader, validation_data=validation_dataloader, epochs=default_values[\"epochs\"], callbacks=[\n",
    "    # To persist the history\n",
    "    keras.callbacks.CSVLogger(f\"{project_definition['name']}_train.csv\", separator=\",\", append=True)\n",
    "])\n",
    "\n",
    "persist_model: bool = True\n",
    "if persist_model:\n",
    "    model.save(f'{project_definition[\"name\"]}.keras')"
   ],
   "id": "bcf7733a80204e47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 365ms/step - accuracy: 0.7020 - loss: 0.6118 - val_accuracy: 0.6959 - val_loss: 0.6511\n",
      "Epoch 2/15\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 355ms/step - accuracy: 0.8361 - loss: 0.3945 - val_accuracy: 0.7328 - val_loss: 0.5574\n",
      "Epoch 3/15\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 353ms/step - accuracy: 0.9033 - loss: 0.2638 - val_accuracy: 0.7529 - val_loss: 0.5250\n",
      "Epoch 4/15\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 365ms/step - accuracy: 0.9413 - loss: 0.2074 - val_accuracy: 0.7709 - val_loss: 0.5212\n",
      "Epoch 5/15\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 362ms/step - accuracy: 0.9546 - loss: 0.1684 - val_accuracy: 0.7603 - val_loss: 0.5291\n",
      "Epoch 6/15\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 365ms/step - accuracy: 0.9744 - loss: 0.1350 - val_accuracy: 0.7719 - val_loss: 0.5170\n",
      "Epoch 7/15\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 371ms/step - accuracy: 0.9810 - loss: 0.1122 - val_accuracy: 0.7856 - val_loss: 0.5204\n",
      "Epoch 8/15\n",
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294ms/step - accuracy: 0.9885 - loss: 0.0941"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# We fix the number of epochs for now. Later we will add early stopping.\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_values\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mepochs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# To persist the history\u001B[39;49;00m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCSVLogger\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mproject_definition\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mname\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_train.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseparator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mappend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m persist_model: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m persist_model:\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:118\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/backend/torch/trainer.py:277\u001B[0m, in \u001B[0;36mTorchTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_epoch_iterator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    268\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_epoch_iterator \u001B[38;5;241m=\u001B[39m TorchEpochIterator(\n\u001B[1;32m    269\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m    270\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    275\u001B[0m         shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    276\u001B[0m     )\n\u001B[0;32m--> 277\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    289\u001B[0m }\n\u001B[1;32m    290\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:118\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/backend/torch/trainer.py:363\u001B[0m, in \u001B[0;36mTorchTrainer.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m    361\u001B[0m logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_metrics()\n\u001B[0;32m--> 363\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mepoch_iterator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menumerate_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_test_batch_begin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:109\u001B[0m, in \u001B[0;36mEpochIterator.enumerate_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    107\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(buffer) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, buffer\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 109\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msteps_per_execution\u001B[49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torch/utils/data/dataset.py:399\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[0;34m(self, indices)\u001B[0m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torchvision/datasets/folder.py:229\u001B[0m, in \u001B[0;36mDatasetFolder.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;124;03m    index (int): Index\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001B[39;00m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    228\u001B[0m path, target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[index]\n\u001B[0;32m--> 229\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    231\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(sample)\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torchvision/datasets/folder.py:268\u001B[0m, in \u001B[0;36mdefault_loader\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accimage_loader(path)\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpil_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/torchvision/datasets/folder.py:248\u001B[0m, in \u001B[0;36mpil_loader\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m    247\u001B[0m     img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(f)\n\u001B[0;32m--> 248\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRGB\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/PIL/Image.py:922\u001B[0m, in \u001B[0;36mImage.convert\u001B[0;34m(self, mode, matrix, dither, palette, colors)\u001B[0m\n\u001B[1;32m    874\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert\u001B[39m(\n\u001B[1;32m    875\u001B[0m     \u001B[38;5;28mself\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, matrix\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dither\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, palette\u001B[38;5;241m=\u001B[39mPalette\u001B[38;5;241m.\u001B[39mWEB, colors\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m\n\u001B[1;32m    876\u001B[0m ):\n\u001B[1;32m    877\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001B[39;00m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;124;03m    method translates pixels through the palette.  If mode is\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    919\u001B[0m \u001B[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001B[39;00m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 922\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    924\u001B[0m     has_transparency \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransparency\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\n\u001B[1;32m    925\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;66;03m# determine default mode\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/PIL/ImageFile.py:291\u001B[0m, in \u001B[0;36mImageFile.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    288\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(msg)\n\u001B[1;32m    290\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[0;32m--> 291\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    293\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:26:47.563892Z",
     "start_time": "2024-05-22T21:26:36.335103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = model.evaluate(test_dataloader)\n",
    "print(f\"Test accuracy is {res[1] * 100:.2f}% while loss is {res[0]}\")"
   ],
   "id": "f3c3ec29ec759820",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:28:39.888483Z",
     "start_time": "2024-05-22T21:28:39.782028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.data_processing import make_loss_graphs, make_loss_accuracy_graphs, add_tuner_iteration_to_data\n",
    "import pandas\n",
    "\n",
    "csv = pandas.read_csv(f\"{project_definition['name']}_train.csv\")\n",
    "add_tuner_iteration_to_data(csv)\n",
    "\n",
    "loss_graph = make_loss_graphs(csv)\n",
    "acc_graph = make_loss_accuracy_graphs(csv)\n",
    "\n",
    "loss_graph.update_layout(title=\"Loss vs Val_loss in tuner search per epoch (Val dashed)\").show()\n",
    "acc_graph.update_layout(title=\"Accuracy vs Val_Accuracy in tuner search per epoch (Val dashed)\").show()"
   ],
   "id": "80ede1dc924cad77",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "# https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting",
   "id": "a67e923f765dca89",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
