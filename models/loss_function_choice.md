> (BCE) Mathematically, it is the preferred loss function under the inference framework of maximum likelihood. It is the loss function to be evaluated first and only changed if you have a good reason.
> https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/
> 
>
Alternative would be using Hinge Loss which:
> The hinge loss function encourages examples to have the correct sign, assigning more error when there is a difference in the sign between the actual and predicted class values