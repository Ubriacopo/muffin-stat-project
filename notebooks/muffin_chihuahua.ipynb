{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "# Why Torch? You'll find the answer in the .md files! \n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:08:42.603385Z",
     "start_time": "2024-03-06T16:08:42.601514Z"
    }
   },
   "id": "7811de1c1a493eba",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:08:43.903648Z",
     "start_time": "2024-03-06T16:08:43.152078Z"
    }
   },
   "id": "f8588985bc8dd55c",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7822445afc86485a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data loading\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# Image size? todo ritornare a 128x128?\n",
    "full_train_dataset = datasets.ImageFolder(\"../data/train\", transform=transforms.Compose([\n",
    "    transforms.Resize((224, 224)), transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "validation_dataset = datasets.ImageFolder(\"../data/test/\", transform=transforms.Compose([\n",
    "    transforms.Resize((224, 224)), transforms.ToTensor()\n",
    "]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:08:45.511028Z",
     "start_time": "2024-03-06T16:08:44.888860Z"
    }
   },
   "id": "a8de3dc5603876b3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Pre processing load\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pre_processing\n\u001B[1;32m      4\u001B[0m sequential_pre_processing_procedure \u001B[38;5;241m=\u001B[39m pre_processing\u001B[38;5;241m.\u001B[39mAugmentationFactory\u001B[38;5;241m.\u001B[39mmake_complete_procedure_keras()\n",
      "File \u001B[0;32m~/PycharmProjects/muffin-stat-keras/utils/pre_processing.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m__future__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m annotations\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping_extensions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deprecated\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mAugmentationProcedure\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/__init__.py:21\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf2\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Pre processing load\n",
    "from utils import pre_processing\n",
    "\n",
    "sequential_pre_processing_procedure = pre_processing.AugmentationFactory.make_complete_procedure_keras()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:08:47.190275Z",
     "start_time": "2024-03-06T16:08:47.066972Z"
    }
   },
   "id": "d771ef5cde65d181",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-FOLD Loading\n",
    "We load data and check if functions work as intended"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "166b836e9500536b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## Naive Model Summary\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnaive_dnn_gen\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnaive_dnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NaiveDnn\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msimple_cnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msimple_cnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SimpleCNN\n\u001B[1;32m      4\u001B[0m naive_model \u001B[38;5;241m=\u001B[39m SimpleCNN((\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m3\u001B[39m), \u001B[38;5;241m2\u001B[39m, augmentation_procedure\u001B[38;5;241m=\u001B[39msequential_pre_processing_procedure)\n",
      "File \u001B[0;32m~/PycharmProjects/muffin-stat-keras/models/naive_dnn_gen/naive_dnn.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layers\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnaive_dnn_pre_process\u001B[39m(input_shape: (\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m), model: keras\u001B[38;5;241m.\u001B[39mModel, augmentation: keras\u001B[38;5;241m.\u001B[39mModel) \\\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mLayer, keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mLayer]:\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/__init__.py:21\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf2\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "## Naive Model Summary\n",
    "from models.naive_dnn_gen.naive_dnn import NaiveDnn\n",
    "from models.simple_cnn.simple_cnn import SimpleCNN\n",
    "naive_model = SimpleCNN((224, 224, 3), 2, augmentation_procedure=sequential_pre_processing_procedure)\n",
    "\n",
    "graph = naive_model.build_graph()\n",
    "graph.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:08:53.046276Z",
     "start_time": "2024-03-06T16:08:53.025994Z"
    }
   },
   "id": "31a65e03f062c680",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "/home/jacopo/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/backend/torch/nn.py:412: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1704987296916/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  outputs = tnn.conv2d(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Exception encountered when calling MaxPooling2D.call().\n\n\u001B[1mGiven input size: (64x1x112). Calculated output size: (64x0x56). Output size is too small\u001B[0m\n\nArguments received by MaxPooling2D.call():\n  • inputs=torch.Tensor(shape=torch.Size([32, 1, 112, 64]), dtype=float32)'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 28\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# I moved to Adam as it is faster\u001B[39;00m\n\u001B[1;32m     26\u001B[0m naive_model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mSGD(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, momentum\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m),\n\u001B[1;32m     27\u001B[0m                     metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, zero_one_loss_binary], loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m i_history \u001B[38;5;241m=\u001B[39m \u001B[43mnaive_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m                                \u001B[49m\u001B[38;5;66;43;03m# To avoid keep going\u001B[39;49;00m\n\u001B[1;32m     31\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEarlyStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mval_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m                                                              \u001B[49m\u001B[43mrestore_best_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \n\u001B[1;32m     34\u001B[0m \u001B[43m                                \u001B[49m\u001B[38;5;66;43;03m# To reduce learning rate (like Hot Stocastic bla bla)\u001B[39;49;00m\n\u001B[1;32m     35\u001B[0m \u001B[43m                                \u001B[49m\u001B[38;5;66;43;03m#keras.callbacks.LearningRateScheduler(\u001B[39;49;00m\n\u001B[1;32m     36\u001B[0m \u001B[43m                                \u001B[49m\u001B[38;5;66;43;03m#    learning_rate_reschedule.learning_rate_reschedule)\u001B[39;49;00m\n\u001B[1;32m     37\u001B[0m \u001B[43m                            \u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m history\u001B[38;5;241m.\u001B[39mappend(i_history)\n\u001B[1;32m     40\u001B[0m naive_model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk-fold-chihuahua-val-fold-\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(i) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:123\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 123\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/keras-pytorch/lib/python3.12/site-packages/keras/src/trainers/trainer.py:923\u001B[0m, in \u001B[0;36mTrainer._symbolic_build\u001B[0;34m(self, iterator, data_batch)\u001B[0m\n\u001B[1;32m    921\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m backend\u001B[38;5;241m.\u001B[39mcompute_output_spec(\u001B[38;5;28mself\u001B[39m, x)\n\u001B[1;32m    922\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 923\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    924\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to automatically build the model. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    925\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease build it yourself before calling \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit/evaluate/predict. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    927\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA model is \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbuilt\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m when its variables have \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    928\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbeen created and its `self.built` attribute \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    929\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis True. Usually, calling the model on a batch \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    930\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof data is the right way to build it.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    931\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mException encountered:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    932\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    933\u001B[0m     )\n\u001B[1;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compile_metrics_unbuilt:\n\u001B[1;32m    935\u001B[0m     \u001B[38;5;66;03m# Build all metric state with `backend.compute_output_spec`.\u001B[39;00m\n\u001B[1;32m    936\u001B[0m     backend\u001B[38;5;241m.\u001B[39mcompute_output_spec(\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics,\n\u001B[1;32m    938\u001B[0m         x,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    941\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[1;32m    942\u001B[0m     )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Exception encountered when calling MaxPooling2D.call().\n\n\u001B[1mGiven input size: (64x1x112). Calculated output size: (64x0x56). Output size is too small\u001B[0m\n\nArguments received by MaxPooling2D.call():\n  • inputs=torch.Tensor(shape=torch.Size([32, 1, 112, 64]), dtype=float32)'"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from k_fold_cv.k_fold_generator import KFoldController\n",
    "from models.naive_dnn_gen.naive_dnn import NaiveDnn\n",
    "from models.simple_cnn.simple_cnn import SimpleCNN\n",
    "from callbacks import learning_rate_reschedule\n",
    "import keras\n",
    "from keras import backend\n",
    "\n",
    "from models.zero_one_validation_loss import zero_one_loss, zero_one_loss_binary\n",
    "\n",
    "FOLDS = 5\n",
    "\n",
    "k_fold_controller = KFoldController(FOLDS)\n",
    "k_fold_controller.load_data(full_train_dataset)\n",
    "\n",
    "history = []\n",
    "\n",
    "# todo function\n",
    "for i in range(FOLDS):\n",
    "    train, val = k_fold_controller.get_data_for_fold(i)\n",
    "    train_dataloader = DataLoader(dataset=train, batch_size=32)\n",
    "    validation_dataloader = DataLoader(dataset=val, batch_size=32)\n",
    "\n",
    "    naive_model = SimpleCNN((224, 224, 3), augmentation_procedure=sequential_pre_processing_procedure)\n",
    "    # I moved to Adam as it is faster\n",
    "    naive_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.5),\n",
    "                        metrics=['accuracy', zero_one_loss_binary], loss='binary_crossentropy')\n",
    "    i_history = naive_model.fit(train_dataloader, epochs=100, validation_data=validation_dataloader,\n",
    "                                callbacks=[\n",
    "                                    # To avoid keep going\n",
    "                                    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,\n",
    "                                                                  restore_best_weights=True),\n",
    "\n",
    "                                    # To reduce learning rate (like Hot Stocastic bla bla)\n",
    "                                    #keras.callbacks.LearningRateScheduler(\n",
    "                                    #    learning_rate_reschedule.learning_rate_reschedule)\n",
    "                                ])\n",
    "    history.append(i_history)\n",
    "\n",
    "    naive_model.save(\"k-fold-chihuahua-val-fold-\" + str(i) + \".keras\")\n",
    "    naive_model.losses.clear()\n",
    "    naive_model.metrics.clear()\n",
    "\n",
    "    # TODO Capisci perche ora va riducendo le chiamate al  minimo indispensabile\n",
    "    # https://github.com/keras-team/keras/issues/5345\n",
    "    torch.cuda.empty_cache()\n",
    "    del naive_model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    #gc.collect()  # Python thing"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T22:41:12.938144Z",
     "start_time": "2024-03-05T22:41:12.258858Z"
    }
   },
   "id": "33d4d76e0e6f764e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "metrics_df1 = pandas.DataFrame(history[0])\n",
    "metrics_df1[[\"loss\", \"val_loss\"]].plot()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96d62db2059237fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "    http://mipal.snu.ac.kr/images/1/16/Dropout_ACCV2016.pdf\n",
    "Dropout"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37d481656b3686f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_dataloader = DataLoader(datasets.ImageFolder(\"../data/train/\", transform=transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])), batch_size=32, shuffle=True)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    datasets.ImageFolder(\"../data/test/\",\n",
    "                         transform=transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "print(label)\n",
    "plt.imshow(img.T, cmap=\"gray\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a222c76a793b3252",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models.simple_neural_network import simple_neural_network\n",
    "\n",
    "model = simple_neural_network((128, 128, 3), 2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.fit(train_dataloader, epochs=150, validation_data=validation_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eca86055051ba381",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b32d36f2ba486b1b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
