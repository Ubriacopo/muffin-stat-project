{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the data from Kaggle\n",
    "\n",
    "To train and evaulate the model we of course need some reference data.\n",
    "\n",
    "The reference dataset is hosted on Kaggle. In order to download it we have to create a connection to the server. This is done via an authorization token created by Kaggle itself. \n",
    "> To generate one simply check the documentation: https://www.kaggle.com/docs/api"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T15:12:13.078781Z",
     "start_time": "2024-05-13T15:12:12.883872Z"
    }
   },
   "source": [
    "from dataset import kaggle_initializer\n",
    "\n",
    "# The provided kaggle.json has to be put under the project data/\n",
    "kaggle_initializer.download_dataset_with_kagglejson(False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jacopo/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/kaggle.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkaggle_initializer\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# The provided kaggle.json has to be put under the project data/\u001B[39;00m\n\u001B[1;32m      3\u001B[0m kaggle_initializer\u001B[38;5;241m.\u001B[39mdownload_dataset_with_kagglejson(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/muffin-stat-project/kaggle_initializer.py:35\u001B[0m\n\u001B[1;32m     32\u001B[0m     kaggle_configuration_data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/kaggle.json\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     33\u001B[0m     download_dataset(kaggle_configuration_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124musername\u001B[39m\u001B[38;5;124m'\u001B[39m], kaggle_configuration_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkey\u001B[39m\u001B[38;5;124m'\u001B[39m], force_download)\n\u001B[0;32m---> 35\u001B[0m \u001B[43mdownload_dataset_with_kagglejson\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/muffin-stat-project/kaggle_initializer.py:32\u001B[0m, in \u001B[0;36mdownload_dataset_with_kagglejson\u001B[0;34m(force_download)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdownload_dataset_with_kagglejson\u001B[39m(force_download: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 32\u001B[0m     kaggle_configuration_data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/kaggle.json\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     33\u001B[0m     download_dataset(kaggle_configuration_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124musername\u001B[39m\u001B[38;5;124m'\u001B[39m], kaggle_configuration_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkey\u001B[39m\u001B[38;5;124m'\u001B[39m], force_download)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/kaggle.json'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images given are already split in two folders: *test* and *train*.\n",
    "\n",
    "Thus, when building the dataset we already have the data split in the two disjointed splits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
