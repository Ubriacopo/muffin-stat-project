{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading the Dataset",
   "id": "31f2627998bc11ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T12:10:35.439554Z",
     "start_time": "2024-05-26T12:10:33.916944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset.dataset_loader import dataset_loader\n",
    "\n",
    "train, test = dataset_loader((224, 224), data_folder_path=\"../data/\")"
   ],
   "id": "fad10df8a5614c91",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Is the dataset balanced?",
   "id": "830be75a14aed4e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T12:10:37.393667Z",
     "start_time": "2024-05-26T12:10:37.391119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "train_muffins = np.sum(train.targets)\n",
    "test_muffins = np.sum(test.targets)"
   ],
   "id": "3853310f9af1e4be",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Muffins are labeled with 1 while chihuahuas are 0. <br />\n",
    "The simplest way to see how many images are muffins is to simply \n",
    "sum all the images with label 1 (or check the file system and the sizes of the sub-folders)"
   ],
   "id": "800b14e758d0b0b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T12:11:03.867529Z",
     "start_time": "2024-05-26T12:11:03.864820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"We have a total of {train_muffins} muffins and {len(train) - train_muffins} chihuahuas in the training set. \"\n",
    "      f\"This results for a ratio of {train_muffins / len(train) * 100:.2f}% of muffins .\")\n",
    "print(f\"We have a total of {test_muffins} muffins and {len(test) - test_muffins} chihuahuas in the testing set.\"\n",
    "      f\"This results for a ratio of {test_muffins / len(test) * 100:.2f}% of chihuahuas .\")"
   ],
   "id": "87887665cf99f658",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 2174 muffins and 2559 chihuahuas in the training set. This results for a ratio of 45.93% of muffins .\n",
      "We have a total of 544 muffins and 640 chihuahuas in the testing set.This results for a ratio of 45.95% of chihuahuas .\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T12:11:06.091252Z",
     "start_time": "2024-05-26T12:11:06.088758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"We have a total of: {len(train) + len(test)} samples, of which {len(test) / (len(train) + len(test)) * 100:.2f}% is in the test set \")"
   ],
   "id": "4aa5180de135479e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of: 5917 samples, of which 20.01% is in the test set \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Does KFold Split evenly?\n",
    "Does my implementation of the K-Fold Cross Validation split the dataset in a desirable way?\n",
    "(Meaning it is correct)"
   ],
   "id": "21784da90ca75e86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T12:12:17.042638Z",
     "start_time": "2024-05-26T12:11:19.811076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset.k_fold_dataset_wrapper import KFoldDatasetWrapper as KFoldController\n",
    "\n",
    "dataset_split_controller = KFoldController(5)\n",
    "dataset_split_controller.load_data(train)\n",
    "\n",
    "local_train, validation = dataset_split_controller.get_data_for_fold(0)\n",
    "\n",
    "k_fold_train = np.sum([local_train[i][1] for i in range(len(local_train))])\n",
    "k_fold_test = np.sum([validation[i][1] for i in range(len(validation))])"
   ],
   "id": "ad1d4cc313fc843c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"We have a total of {k_fold_train} and {len(local_train) - k_fold_train} muffins in the training set. \"\n",
    "      f\"This results for a ratio of {k_fold_train / len(local_train) * 100:.2f}% of chihuahuas .\")\n",
    "print(f\"We have a total of {k_fold_test} and {len(validation) - k_fold_test} muffins in the testing set.\"\n",
    "      f\"This results for a ratio of {k_fold_test / len(validation) * 100:.2f}% of chihuahuas .\")"
   ],
   "id": "81d7148af1e4d408",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Normalizing the dataset\n",
    "Normalizing the data has the advantage of speeding up the training."
   ],
   "id": "b073c00701d42632"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:22:08.129364Z",
     "start_time": "2024-05-22T18:22:08.001116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset.dataset_loader import dataset_loader\n",
    "\n",
    "# Load the datasets to measure the mean and std\n",
    "train, test = dataset_loader((224, 224), data_folder_path=\"../data/\")"
   ],
   "id": "dd29f9e9c60c041d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ">  Common pitfall. An important point to make about the preprocessing is that any preprocessing statistics\n",
    "     (e.g. the data mean) must only be computed on the training data, and then applied to the validation / test data.\n",
    "     E.g. computing the mean and subtracting it from every image across the entire dataset and then splitting\n",
    "     the data into train/val/test splits would be a mistake. Instead, the mean must be computed only over the\n",
    "     training data and then subtracted equally from all splits (train/val/test).\n",
    ">     \n",
    ">              ~ https://cs231n.github.io/neural-networks-2/ (Data Preprocessing)\n",
    "\n",
    "\n",
    "Because of this pitfall when doing K-fold CV or diving the dataset in train/validation we will have to compute the values again and pass them to the model in an augmentation procedure."
   ],
   "id": "b6846df8238982ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:18:22.375953Z",
     "start_time": "2024-05-22T15:17:38.495104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset_loader import dataset_information\n",
    "\n",
    "res = dataset_information(train, (224, 224))"
   ],
   "id": "5840de96a5502ca2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:18:49.080938Z",
     "start_time": "2024-05-22T15:18:49.078401Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"The training dataset has means: {res[0]} and stds: {res[1]} (w.r.t. the channels)\")",
   "id": "261dc7577dcc1269",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has means: tensor([0.6501, 0.5935, 0.5400]) and stds: tensor([0.2951, 0.3003, 0.3205]) (w.r.t. the channels)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These values are stored in the dataset_loader.py file as a dictionary.",
   "id": "63cf9fdc2f8d2717"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
